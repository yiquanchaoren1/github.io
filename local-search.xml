<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>project05</title>
    <link href="/2024/09/09/project05/"/>
    <url>/2024/09/09/project05/</url>
    
    <content type="html"><![CDATA[<h3 id="find-the-error"><a href="#find-the-error" class="headerlink" title="find the error"></a>find the error</h3><p>程序运行慢的原因：申请的block数太多了，可能线程等待什么的需要时间。</p><p>改完后要比c快很多。</p><p>计算误差</p><p>225轮测试基本没有误差。</p><p><img src="/../images/1725885874956.png" alt="1725885874956"></p><p>时间：225 轮</p><p>hip : 16min      f 走了94轮</p><p>快一倍不止</p><p>时间：5025轮</p><p>差不多三倍</p><h3 id="前期优化已经完成，后期优化方向"><a href="#前期优化已经完成，后期优化方向" class="headerlink" title="前期优化已经完成，后期优化方向"></a>前期优化已经完成，后期优化方向</h3><p>设置合适的block和thread</p><p>合并内存访问</p><p>bank冲突</p><p>shared memory</p><p>寄存器</p><p>多dcu</p><p>多节点</p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>project04</title>
    <link href="/2024/09/08/project04/"/>
    <url>/2024/09/08/project04/</url>
    
    <content type="html"><![CDATA[<p>找到了，真的不好发现吧。</p><p><img src="/../images/1725778438293.png" alt="1725778438293"></p><p>Flux_xyz_FVM这里是<code>FLuidtwo </code>，为什么我写了两个<code>FLuidone</code></p><p>在验证一下US和RK，都没问题了，就再写成hip，然后再将两个equation写成一个，减少数据传输。有些值不用传回来。</p><p>US没问题</p><p>RK没问题</p><p>跑一步要十五分钟？</p><p>更改的数组有哪些？</p><p>Flux_FVM_US：<br>den 等数组赋值给flux_US</p><p>Flux_xyz:<br>den 等数组和flux_US赋值给flux<br>flux赋值给Lcon</p><p>Euler_equ_RK:<br>flux_US等数组赋值给con</p><p>只有这几个</p><p>flux_US，flux，Lcon，con</p><p>所以说其他的数组和值没变，不用传回来。</p><p>全部传回来：15min</p><p>只传改过的数组：快一点，没快多少。说明传输占用的时间不多。</p><p>两个eqation是eq2文件中的代码</p><p>改为一个equation，写成3D_Cut-Cell_hip_p</p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>project03</title>
    <link href="/2024/09/07/project03/"/>
    <url>/2024/09/07/project03/</url>
    
    <content type="html"><![CDATA[<p>对比两个代码<code>Flux_x_FVM1.c    Flux_x_FVM.c</code>没有发现任何问题。</p><p>计算机内部发生了什么。</p><p><img src="/../images/1725601244759.png" alt="1725601244759"></p><p>对应c，k,j,i  &#x3D; 27 ,22 ,27</p><p>根据下标找不太现实。</p><p>在指定的位置输出，比较两个文件的数据，每一行一个数据，检查偏移量是不是计算有错误。</p><p>只改x和y，输出的内容是一样的，说明这个错误在两个函数里面都有。</p><p>输出了x里面fluid &#x3D; 1 的值，没有问题。</p><p>输出下 fluid &#x3D; 2;</p><p>在特定的地方输出了一些数据，和原始数组作对比</p><p>do istep</p><p>do RK</p><p>RK &#x3D; 1</p><p>flux  Y</p><p>fluid 1 flux1 </p><p>fluid 1 flux2 </p><p>fluid 1 Lcon </p><p>flux  Y</p><p>Y fluid 2 flux1</p><p>fluid 2 flux2</p><p>fluid 2 Lcon </p><p>RK  &#x3D;2 </p><p>flux </p><p>fluid 1 flux1  Y</p><p>fluid 1 flux2 Y</p><p>fluid 1 Lcon  Y</p><p>dL算完是对</p><p>Y flux N 这里，前后不一致，只能是其他的参数传入错误，或者函数本身有错误（函数本身没变，几率小）</p><p>N fluid 2 flux1</p><p>fluid 2 flux2</p><p>Y fluid 2 Lcon N</p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>project02</title>
    <link href="/2024/09/05/project02/"/>
    <url>/2024/09/05/project02/</url>
    
    <content type="html"><![CDATA[<p><img src="/../images/1725510566478.png" alt="1725510566478"></p><p>invflux函数不是US特有的，把US转成hip的时候，子函数怎么处理呢？因为其他函数还要用。</p><p>编译两个函数，cpu and dcu. invflux.o  and invflux1.o</p><p><img src="/../images/1725518462734.png" alt="1725518462734"></p><p>这个问题是，传入的是数组的指针，而函数原型期望的是一个具体的数组，具有明确的维度。这种情况下，C++ 编译器会抱怨类型不匹配，因为指针和数组并不完全等价，特别是当数组是多维数组时。</p><p>这个应该是c++的问题。.c 没有问题。</p><p>但是如果不把equation改成.cpp，就不能用hip</p><p>挺麻烦的。</p><p>把所有的数组都改成一维的吧。不然太容易出事了。</p><p>步骤：</p><p>不考虑hip，逐个函数改成一维数组。改完验证。</p><p><img src="/../images/1725528962350.png" alt="1725528962350"></p><p>把Flux_FVM_xyz 转为一维后error</p><p>找到具体的函数。</p><p>先把xyz全加上，都用之前的。</p><p>感觉还是多维数组转一维的时候计算出了问题，偏移量？for循环？</p><p>只改Flux_FVM_x，</p><p><img src="/../images/1725539404148.png" alt="1725539404148"></p><p>说明是Flux_FVM_x里面的问题。</p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>project01</title>
    <link href="/2024/09/04/project01/"/>
    <url>/2024/09/04/project01/</url>
    
    <content type="html"><![CDATA[<p>把所有的全局变量通过参数的形式传入函数。</p><p><img src="/../images/1725455051738.png" alt="1725455051738"></p><p>这些值，改完后运行没有问题。</p><p>后面试一下混编，c和c++一起，生成一个动态链接库。</p><p>c不行的话，后缀都改成cpp</p><p>先在<code>euler_equation_fvm_c_</code>里面加上extern “C”，混编要注意编译选项的问题。</p><p>一个函数一个函数测试，先从US开始。</p><p>找到具体的dcu bug在哪个地方。</p><p>tip： 研究生能不能取消导师制度，学生不是老师压榨的工具。</p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《幻夜》</title>
    <link href="/2024/09/04/%E5%B9%BB%E5%A4%9C/"/>
    <url>/2024/09/04/%E5%B9%BB%E5%A4%9C/</url>
    
    <content type="html"><![CDATA[<p>我们不是说好了吗，两个人要斗争到底。周围全是敌人。我们为了生存下去，无法干高尚的事。</p><p>为什么背叛，为什么杀死我的灵魂，你说我们没有白昼，任何时候都是黑夜，说过我们要在黑夜中生存下去。</p><p>即便如此，我也无所谓，只要是真正的黑夜就行。然而，你连那个都没有给我，你给予我的全是虚幻。</p><p><img src="/../images/1725423808559.png" alt="1725423808559"></p><p>看这本书的时候，越看越像东野圭吾老师的另一本书《白夜行》。雅也从杀死舅舅的那一刻就走上了一条不归路，爱上了美冬，在黑夜中帮助他。”像我们这样的人，为了我们的未来我们，我们必须这么做“，雅也想起美冬的话，他不能回头了。美冬说的未来究竟是什么，他也不知道，有一件事他是明白的，他们不可能过上和正常人一样的生活了，只能在黑暗中一直前行。</p><blockquote><p><strong>“即使四周明亮有如白昼，那也只是假象”</strong><br><strong>“就算与你共度的每个夜晚都是假象，我也愿为你化身为影，至死不渝。”</strong></p></blockquote><p><strong>是雅也对美冬的告白。</strong></p><p>她是个贪婪的人，无情地想要得到身边的一切，不惜任何代价。没有道德，没有下线，没有感情，她甚至都忘记了什么是爱。</p><p>他救过她，为她付出了生命中的一切。甚至在知道被她背叛后，知道自己只是她的一个工具的时候。直到生命的最后一刻，他还在保护着她。</p><p>文章的最后。“这么美好的夜晚还是第一次看到，简直像幻夜一般。”说着，她露出妖媚的笑容。</p><p>《白夜行》的最后，桐原亮司的死带走了她最后一丝光，白夜已经消逝。<br>《幻夜》的最后，水原雅也的死点缀了她的世界，幻夜才刚刚开始。</p>]]></content>
    
    
    <categories>
      
      <category>book</category>
      
    </categories>
    
    
    <tags>
      
      <tag>book</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>项目c转hip</title>
    <link href="/2024/07/14/%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96/"/>
    <url>/2024/07/14/%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="思路分析"><a href="#思路分析" class="headerlink" title="思路分析"></a>思路分析</h2><p>head_hip目录中.h文件<br>1.声明核函数（__global__函数）和__device__函数和c函数<br>实现在具体的.cpp代码中<br>2.声明全局参数</p><p>src_hip目录中.cpp文件<br>1.导入声明核函数和c函数的.h头文件。<br>2.实现核函数。调用__device__函数。__device__函数在本代码实现，用于核函数中调用。<br>3.实现c函数。调用本代码的核函数或者其他地方实现的核函数。</p><p>整体思路就是把数据初始化和计算的部分用核函数实现，其他的地方保持不变。把__device__函数和__global__函数在.h文件声明，然后在具体的.cpp文件中实现。<br>我的想法就是先在Equation里面把用到的数据传到gpu，然后Equation调用的那五个函数。每个函数里面都有三重for循环。每次循环之间都是独立的。把这三重for循环写成一个核函数，每个线程处理其中的几个循环。其中调用的子函数写成__device__函数。<br>还有就是c转为hip，数组要展开成一维的，设置下标索引对应。<br>结构图我画不出来，就是主函数调用其他函数，然后继续调用，把初始化和计算的部分写成核函数。<br>两个Equation外面加一个父函数，在父函数中进行数据传输，这样只用传输一次数据。</p><h3 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h3><h4 id="什么时候传入？"><a href="#什么时候传入？" class="headerlink" title="什么时候传入？"></a>什么时候传入？</h4><p>有两个Equation，数据传输不要写在Equation里面，因为有两个Equation，这样就要数据传输两次，在Equation调用之前进行数据传输。因为整个过程是封装在动态链接库中，所以要在给Equation加一个父函数，父函数调用Equation，在父函数中进行数据传输，父函数为动态链接库的主函数。</p><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><h4 id="1-先写出这个父函数。定义：PEquation"><a href="#1-先写出这个父函数。定义：PEquation" class="headerlink" title="1.先写出这个父函数。定义：PEquation"></a>1.先写出这个父函数。定义：PEquation</h4><p>3D_Cut-Cell_hip</p><h4 id="2-在父函数中将数据传入GPU"><a href="#2-在父函数中将数据传入GPU" class="headerlink" title="2.在父函数中将数据传入GPU"></a>2.在父函数中将数据传入GPU</h4><p>传入哪些数据？</p><p>参与计算的数据</p><h4 id="数组的下标怎么对应"><a href="#数组的下标怎么对应" class="headerlink" title="数组的下标怎么对应"></a>数组的下标怎么对应</h4><p>CPU传入GPU，直接传，但是传入的数组是一维的。在device或global函数中用到该数组的时候，在一维数组利用索引对应到操作到多维数组的下标。</p><p>threadPerBlock 最大256</p><p>一个线程处理for循环的一次</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime_api.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NX 10</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NY 10</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NZ 10</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> W 3</span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">processKernel</span><span class="hljs-params">(<span class="hljs-type">int</span>* imark, <span class="hljs-type">int</span>* cut_model, <span class="hljs-type">float</span>* xyzside, <span class="hljs-type">int</span> nx, <span class="hljs-type">int</span> ny, <span class="hljs-type">int</span> nz, <span class="hljs-type">int</span> w, </span></span><br><span class="hljs-params"><span class="hljs-function">                              <span class="hljs-type">int</span> inter_iL, <span class="hljs-type">int</span> inter_iR, <span class="hljs-type">int</span> inter_jL, <span class="hljs-type">int</span> inter_jR, <span class="hljs-type">int</span> inter_kL, <span class="hljs-type">int</span> inter_kR,</span></span><br><span class="hljs-params"><span class="hljs-function">                              <span class="hljs-type">int</span>* counter)</span> </span>&#123;<br>    <span class="hljs-type">int</span> k = blockIdx.z * blockDim.z + threadIdx.z;<br>    <span class="hljs-type">int</span> j = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br><br>    <span class="hljs-keyword">if</span> (k &gt;= inter_kL &amp;&amp; k &lt;= inter_kR &amp;&amp;<br>        j &gt;= inter_jL &amp;&amp; j &lt;= inter_jR &amp;&amp;<br>        i &gt;= inter_iL &amp;&amp; i &lt;= inter_iR) &#123;<br><br>        <span class="hljs-type">int</span> index3D = k * (ny * nx) + j * nx + i;<br>        imark[index3D] += cut_model[index3D];<br>        <br>        <br>        <span class="hljs-type">int</span> index4D = k * (ny * nx * w) + j * (nx * w) + i * w;<br>        <span class="hljs-comment">//操作4维数组</span><br>        xyzside[index4D + <span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>        xyzside[index4D + <span class="hljs-number">1</span>] = <span class="hljs-number">2</span>;<br>        xyzside[index4D + <span class="hljs-number">2</span>] = <span class="hljs-number">3</span>;<br><br><br>       <br><br>        <span class="hljs-comment">// 更新计数器</span><br>        <span class="hljs-built_in">atomicAdd</span>(counter, <span class="hljs-number">1</span>);<br>    &#125;<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 定义数组大小</span><br>    <span class="hljs-type">int</span> nx = NX, ny = NY, nz = NZ, w = W;<br>    <span class="hljs-type">int</span> arraySize3D = nx * ny * nz;<br>    <span class="hljs-type">int</span> arraySize4D = nx * ny * nz * w;<br><br>    <span class="hljs-comment">// 分配并初始化CPU上的数组</span><br>    <span class="hljs-type">int</span>* h_imark = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize3D];<br>    <span class="hljs-type">int</span>* h_cut_model = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize3D];<br>    <span class="hljs-type">float</span>* h_xyzside = <span class="hljs-keyword">new</span> <span class="hljs-type">float</span>[arraySize4D];<br><br>    <span class="hljs-comment">// 初始化数组</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize3D; i++) &#123;<br>        h_imark[i] = <span class="hljs-number">0</span>;<br>        h_cut_model[i] = <span class="hljs-number">-99</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize4D; i++) &#123;<br>        h_xyzside[i] = <span class="hljs-number">0.0f</span>;<br>    &#125;<br><br>    <span class="hljs-comment">// 分配GPU内存</span><br>    <span class="hljs-type">int</span>* d_imark;<br>    <span class="hljs-type">int</span>* d_cut_model;<br>    <span class="hljs-type">float</span>* d_xyzside;<br>    <span class="hljs-type">int</span>* d_counter;<br>    <span class="hljs-type">int</span> h_counter = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><br>    <span class="hljs-comment">// 将数据从CPU传输到GPU</span><br>    <span class="hljs-built_in">hipMemcpy</span>(d_imark, h_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_cut_model, h_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_xyzside, h_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_counter, &amp;h_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br><br>    <span class="hljs-comment">// 定义线程块和网格的大小</span><br>    <span class="hljs-comment">//一个block最大线程256</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>)</span></span>;<br>    <span class="hljs-comment">//根据问题的规模确定定义几个线程块</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">blocksPerGrid</span><span class="hljs-params">((nx + threadsPerBlock.x - <span class="hljs-number">1</span>) / threadsPerBlock.x,</span></span><br><span class="hljs-params"><span class="hljs-function">                       (ny + threadsPerBlock.y - <span class="hljs-number">1</span>) / threadsPerBlock.y,</span></span><br><span class="hljs-params"><span class="hljs-function">                       (nz + threadsPerBlock.z - <span class="hljs-number">1</span>) / threadsPerBlock.z)</span></span>;<br><br>    <span class="hljs-comment">// 调用CUDA内核函数</span><br>    <span class="hljs-type">int</span> inter_iL = <span class="hljs-number">0</span>, inter_iR = nx - <span class="hljs-number">1</span>, inter_jL = <span class="hljs-number">0</span>, inter_jR = ny - <span class="hljs-number">1</span>, inter_kL = <span class="hljs-number">0</span>, inter_kR = nz - <span class="hljs-number">1</span>;<br>    processKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_imark, d_cut_model, d_xyzside, nx, ny, nz, w, <br>                                                      inter_iL, inter_iR, inter_jL, inter_jR, inter_kL, inter_kR, d_counter);<br><br>    <span class="hljs-comment">// 等待GPU完成</span><br>    <span class="hljs-built_in">hipDeviceSynchronize</span>();<br><br>    <span class="hljs-comment">// 将结果从GPU传回CPU</span><br>    <span class="hljs-built_in">hipMemcpy</span>(h_imark, d_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_cut_model, d_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_xyzside, d_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(&amp;h_counter, d_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br><br>    <span class="hljs-comment">// 检查计数器</span><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Total elements processed: &quot;</span> &lt;&lt; h_counter &lt;&lt; std::endl;<br><br>    <span class="hljs-comment">// 打印结果（如果需要）</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize3D; i++) &#123;<br>        std::cout &lt;&lt; h_imark[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize4D; i++) &#123;<br>        std::cout &lt;&lt; h_xyzside[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br><br>    <span class="hljs-comment">// 释放GPU内存</span><br>    <span class="hljs-built_in">hipFree</span>(d_imark);<br>    <span class="hljs-built_in">hipFree</span>(d_cut_model);<br>    <span class="hljs-built_in">hipFree</span>(d_xyzside);<br>    <span class="hljs-built_in">hipFree</span>(d_counter);<br><br>    <span class="hljs-comment">// 释放CPU内存</span><br>    <span class="hljs-keyword">delete</span>[] h_imark;<br>    <span class="hljs-keyword">delete</span>[] h_cut_model;<br>    <span class="hljs-keyword">delete</span>[] h_xyzside;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><h4 id="子函数写成device形式，通过参数传入线程号。"><a href="#子函数写成device形式，通过参数传入线程号。" class="headerlink" title="子函数写成device形式，通过参数传入线程号。"></a>子函数写成device形式，通过参数传入线程号。</h4><p>可能不需要传入线程号，把要操作的数组传入即可。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime_api.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NX 10</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NY 10</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NZ 10</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> W 3</span><br><span class="hljs-function">__device__ <span class="hljs-type">void</span> <span class="hljs-title">fun_dev1</span><span class="hljs-params">(<span class="hljs-type">int</span>* dL,<span class="hljs-type">int</span> xyzside)</span></span>&#123;<br>    *dL = xyzside;<br>&#125;<br><span class="hljs-function">__device__ <span class="hljs-type">void</span> <span class="hljs-title">fun_dev2</span><span class="hljs-params">(<span class="hljs-type">int</span> dL,<span class="hljs-type">int</span>* array1)</span></span>&#123;<br>    *array1 = dL;<br><br>&#125;<br><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">processKernel</span><span class="hljs-params">(<span class="hljs-type">int</span>* imark, <span class="hljs-type">int</span>* cut_model, <span class="hljs-type">int</span>* xyzside,<span class="hljs-type">int</span>* array1D,<span class="hljs-type">int</span>* array2D,<span class="hljs-type">int</span>* array1,<span class="hljs-type">int</span> nx, <span class="hljs-type">int</span> ny, <span class="hljs-type">int</span> nz, <span class="hljs-type">int</span> w, </span></span><br><span class="hljs-params"><span class="hljs-function">                              <span class="hljs-type">int</span> inter_iL, <span class="hljs-type">int</span> inter_iR, <span class="hljs-type">int</span> inter_jL, <span class="hljs-type">int</span> inter_jR, <span class="hljs-type">int</span> inter_kL, <span class="hljs-type">int</span> inter_kR,</span></span><br><span class="hljs-params"><span class="hljs-function">                              <span class="hljs-type">int</span>* counter)</span> </span>&#123;<br>    <span class="hljs-type">int</span> k = blockIdx.z * blockDim.z + threadIdx.z;<br>    <span class="hljs-type">int</span> j = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    <br>    <span class="hljs-type">int</span> dL;<br>    <br>    <br>    <span class="hljs-comment">//三维数组的范围[nz][ny][nx],nz = inter_kR...,保证不越界</span><br>    <span class="hljs-keyword">if</span> (k &gt;= inter_kL &amp;&amp; k &lt;= inter_kR &amp;&amp;<br>        j &gt;= inter_jL &amp;&amp; j &lt;= inter_jR &amp;&amp;<br>        i &gt;= inter_iL &amp;&amp; i &lt;= inter_iR) &#123;<br><br>        <span class="hljs-type">int</span> index3D = k * (ny * nx) + j * nx + i;<br>        imark[index3D] += cut_model[index3D];<br>        <span class="hljs-type">int</span> index4D = k * (ny * nx * w) + j * (nx * w) + i * w;<br>        xyzside[index4D + <span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>        xyzside[index4D + <span class="hljs-number">1</span>] = <span class="hljs-number">2</span>;<br>        xyzside[index4D + <span class="hljs-number">2</span>] = <span class="hljs-number">3</span>;<br><br>        <span class="hljs-comment">//调用device函数,将xyzside[k][j][i][0]的值赋给dL</span><br>        <span class="hljs-built_in">fun_dev1</span>(&amp;dL,xyzside[index4D + <span class="hljs-number">0</span>]);<br>        <span class="hljs-comment">//调用device函数，再将dL的值传给一维数组,no ploblem</span><br>        <span class="hljs-built_in">fun_dev2</span>(dL,array1[index3D]);<br><br><br>        <br>        <span class="hljs-comment">// 更新计数器</span><br>        <span class="hljs-built_in">atomicAdd</span>(counter, <span class="hljs-number">1</span>);<br>    &#125;<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 定义数组大小</span><br>    <span class="hljs-type">int</span> nx = NX, ny = NY, nz = NZ, w = W;<br>    <span class="hljs-type">int</span> arraySize3D = nx * ny * nz;<br>    <span class="hljs-type">int</span> arraySize4D = nx * ny * nz * w;<br>    <span class="hljs-type">int</span> arraySize2D = nx * ny;<br>    <span class="hljs-type">int</span> arraySize1D = nx;<br>    <br><br>    <span class="hljs-comment">// 分配并初始化CPU上的数组</span><br>    <span class="hljs-type">int</span>* h_imark = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize3D];<br>    <span class="hljs-type">int</span>* h_cut_model = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize3D];<br>    <span class="hljs-type">int</span>* h_xyzside = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize4D];<br>    <span class="hljs-type">int</span>* h_array2D = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize2D];<br>    <span class="hljs-type">int</span>* h_array1D = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize1D];<br>    <span class="hljs-type">int</span>* h_array1 = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize3D];<br><br><br>    <span class="hljs-comment">// 初始化数组</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize3D; i++) &#123;<br>        h_imark[i] = <span class="hljs-number">0</span>;<br>        h_cut_model[i] = <span class="hljs-number">-99</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize4D; i++) &#123;<br>        h_xyzside[i] = <span class="hljs-number">0.0f</span>;<br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;arraySize2D;i++)&#123;<br>        h_array2D[i] = <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;arraySize1D;i++)&#123;<br>        h_array1D[i] = <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;arraySize3D;i++)&#123;<br>        h_array1[i] = <span class="hljs-number">0</span>;<br>    &#125;<br>    <br><br><br>    <span class="hljs-comment">// 分配GPU内存</span><br>    <span class="hljs-type">int</span>* d_imark;<br>    <span class="hljs-type">int</span>* d_cut_model;<br>    <span class="hljs-type">int</span>* d_xyzside;<br>    <span class="hljs-type">int</span>* d_counter;<br>    <span class="hljs-type">int</span>* d_array2D;<br>    <span class="hljs-type">int</span>* d_array1D;<br>    <span class="hljs-type">int</span>* d_array1;<br>    <span class="hljs-type">int</span> h_counter = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_array2D,arraySize2D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_array1D,arraySize1D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_array1,arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><br><br>    <span class="hljs-comment">// 将数据从CPU传输到GPU</span><br>    <span class="hljs-built_in">hipMemcpy</span>(d_imark, h_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_cut_model, h_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_xyzside, h_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_array2D,h_array2D,arraySize2D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_array1D,h_array1D,arraySize1D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_array1,h_array1,arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_counter, &amp;h_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br><br>    <span class="hljs-comment">// 定义线程块和网格的大小</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">blocksPerGrid</span><span class="hljs-params">((nx + threadsPerBlock.x - <span class="hljs-number">1</span>) / threadsPerBlock.x,</span></span><br><span class="hljs-params"><span class="hljs-function">                       (ny + threadsPerBlock.y - <span class="hljs-number">1</span>) / threadsPerBlock.y,</span></span><br><span class="hljs-params"><span class="hljs-function">                       (nz + threadsPerBlock.z - <span class="hljs-number">1</span>) / threadsPerBlock.z)</span></span>;<br><br>    <span class="hljs-comment">// 调用CUDA内核函数</span><br>    <span class="hljs-type">int</span> inter_iL = <span class="hljs-number">0</span>, inter_iR = nx - <span class="hljs-number">1</span>, inter_jL = <span class="hljs-number">0</span>, inter_jR = ny - <span class="hljs-number">1</span>, inter_kL = <span class="hljs-number">0</span>, inter_kR = nz - <span class="hljs-number">1</span>;<br>    processKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_imark, d_cut_model, d_xyzside,d_array1D,d_array2D, d_array1,nx, ny, nz, w, <br>                                                      inter_iL, inter_iR, inter_jL, inter_jR, inter_kL, inter_kR, d_counter);<br><br>    <span class="hljs-comment">// 等待GPU完成</span><br>    <span class="hljs-built_in">hipDeviceSynchronize</span>();<br><br>    <span class="hljs-comment">// 将结果从GPU传回CPU</span><br>    <span class="hljs-built_in">hipMemcpy</span>(h_imark, d_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_cut_model, d_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_xyzside, d_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_array2D,d_array2D,arraySize2D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_array2D,d_array2D,arraySize2D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_array1,d_array1,arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(&amp;h_counter, d_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br><br>    <span class="hljs-comment">// 检查计数器</span><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Total elements processed: &quot;</span> &lt;&lt; h_counter &lt;&lt; std::endl;<br><br>    <span class="hljs-comment">// 打印结果（如果需要）</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize3D; i++) &#123;<br>        std::cout &lt;&lt; h_imark[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize4D; i++) &#123;<br>        std::cout &lt;&lt; h_xyzside[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br>    <br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt; arraySize2D;i++)&#123;<br>        std::cout &lt;&lt; h_array2D[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt; arraySize1D;i++)&#123;<br>        std::cout &lt;&lt; h_array1D[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize3D; i++) &#123;<br>        std::cout &lt;&lt; h_array1[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br><br><br>    <span class="hljs-comment">// 释放GPU内存</span><br>    <span class="hljs-built_in">hipFree</span>(d_imark);<br>    <span class="hljs-built_in">hipFree</span>(d_cut_model);<br>    <span class="hljs-built_in">hipFree</span>(d_xyzside);<br>    <span class="hljs-built_in">hipFree</span>(d_array2D);<br>    <span class="hljs-built_in">hipFree</span>(d_array1D);<br>    <span class="hljs-built_in">hipFree</span>(d_counter);<br><br>    <span class="hljs-comment">// 释放CPU内存</span><br>    <span class="hljs-keyword">delete</span>[] h_imark;<br>    <span class="hljs-keyword">delete</span>[] h_cut_model;<br>    <span class="hljs-keyword">delete</span>[] h_xyzside;<br>    <span class="hljs-keyword">delete</span>[] h_array1D;<br>    <span class="hljs-keyword">delete</span>[] h_array2D;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="待解决的问题"><a href="#待解决的问题" class="headerlink" title="待解决的问题"></a>待解决的问题</h3><p>把后缀改成.c++，c++函数调用，参数不匹配的问题。可能是需要导入定义函数的头文件。c++里面</p><p>下标对应问题，问题规模，for循环的参数.</p><p>ijk不是对应的数组的下标，而是对应三重for循环，每一次for循环对应一次数组下标。再做相应操作</p><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p>第三维度是nz</p><p><img src="/../images/1721198547896.png" alt="1721198547896"></p><p>k,对应第三维，即<strong>k对应nz</strong></p><p><img src="/../images/1721198572456.png" alt="1721198572456"></p><p>数组大小为<code>[nz][ny][nx]</code>,所以对应<code>[k][j][i]</code>,对应正确</p><p><img src="/../images/1721198641452.png" alt="1721198641452"></p><p>nz ny nx 是数组的大小 </p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime_api.h&gt;</span></span><br><span class="hljs-comment">//每层for循环的大小</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NZ 15</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NY 10</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NX 10</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> W 3</span><br><span class="hljs-function">__device__ <span class="hljs-type">void</span> <span class="hljs-title">fun_dev1</span><span class="hljs-params">(<span class="hljs-type">int</span>* dL,<span class="hljs-type">int</span> xyzside)</span></span>&#123;<br>    *dL = xyzside;<br>&#125;<br><span class="hljs-function">__device__ <span class="hljs-type">void</span> <span class="hljs-title">fun_dev2</span><span class="hljs-params">(<span class="hljs-type">int</span> dL,<span class="hljs-type">int</span>* array1)</span></span>&#123;<br>    *array1 = dL;<br><br>&#125;<br><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">processKernel</span><span class="hljs-params">(<span class="hljs-type">int</span>* imark, <span class="hljs-type">int</span>* cut_model, <span class="hljs-type">int</span>* xyzside,<span class="hljs-type">int</span>* array1D,<span class="hljs-type">int</span>* array2D,<span class="hljs-type">int</span>* array1,<span class="hljs-type">int</span> nx, <span class="hljs-type">int</span> ny, <span class="hljs-type">int</span> nz, <span class="hljs-type">int</span> w, </span></span><br><span class="hljs-params"><span class="hljs-function">                              <span class="hljs-type">int</span> inter_iL, <span class="hljs-type">int</span> inter_iR, <span class="hljs-type">int</span> inter_jL, <span class="hljs-type">int</span> inter_jR, <span class="hljs-type">int</span> inter_kL, <span class="hljs-type">int</span> inter_kR,</span></span><br><span class="hljs-params"><span class="hljs-function">                              <span class="hljs-type">int</span>* counter)</span> </span>&#123;<br>    <span class="hljs-type">int</span> k = blockIdx.z * blockDim.z + threadIdx.z;<br>    <span class="hljs-type">int</span> j = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    <br>    <span class="hljs-type">int</span> dL;<br>    <br>    <br>    <span class="hljs-comment">//三维数组的范围[nz][ny][nx],nz = inter_kR...,保证不越界</span><br>    <span class="hljs-keyword">if</span> (k &gt;= inter_kL &amp;&amp; k &lt;= inter_kR &amp;&amp;<br>        j &gt;= inter_jL &amp;&amp; j &lt;= inter_jR &amp;&amp;<br>        i &gt;= inter_iL &amp;&amp; i &lt;= inter_iR) &#123;<br><br>        <span class="hljs-type">int</span> index3D = k * (ny * nx) + j * nx + i;<br>        imark[index3D] += cut_model[index3D];<br>        <span class="hljs-type">int</span> index4D = k * (ny * nx * w) + j * (nx * w) + i * w;<br>        xyzside[index4D + <span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>        xyzside[index4D + <span class="hljs-number">1</span>] = <span class="hljs-number">2</span>;<br>        xyzside[index4D + <span class="hljs-number">2</span>] = <span class="hljs-number">3</span>;<br><br>        <span class="hljs-comment">//调用device函数,将xyzside[k][j][i][0]的值赋给dL</span><br>        <span class="hljs-comment">//fun_dev1(&amp;dL,xyzside[index4D + 0]);</span><br>        <span class="hljs-comment">//调用device函数，再将dL的值传给一维数组</span><br>        <span class="hljs-comment">//fun_dev2(dL,&amp;array1[index3D]);</span><br><br><br>        <br>        <span class="hljs-comment">// 更新计数器</span><br>        <span class="hljs-built_in">atomicAdd</span>(counter, <span class="hljs-number">1</span>);<br>    &#125;<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 定义数组大小</span><br>    <span class="hljs-type">int</span> nx = NX+<span class="hljs-number">4</span>, ny = NY+<span class="hljs-number">4</span>, nz = NZ+<span class="hljs-number">4</span>, w = W;<br>    <span class="hljs-type">int</span> arraySize3D = nx * ny * nz;<br>    <span class="hljs-type">int</span> arraySize4D = nx * ny * nz * w;<br>    <span class="hljs-type">int</span> arraySize2D = nx * ny;<br>    <span class="hljs-type">int</span> arraySize1D = nx;<br>    <br><br>    <span class="hljs-comment">// 分配并初始化CPU上的数组</span><br>    <span class="hljs-type">int</span>* h_imark = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize3D];<br>    <span class="hljs-type">int</span>* h_cut_model = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize3D];<br>    <span class="hljs-type">int</span>* h_xyzside = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize4D];<br>    <span class="hljs-type">int</span>* h_array2D = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize2D];<br>    <span class="hljs-type">int</span>* h_array1D = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize1D];<br>    <span class="hljs-type">int</span>* h_array1 = <span class="hljs-keyword">new</span> <span class="hljs-type">int</span>[arraySize3D];<br><br><br>    <span class="hljs-comment">// 初始化数组</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize3D; i++) &#123;<br>        h_imark[i] = <span class="hljs-number">0</span>;<br>        h_cut_model[i] = <span class="hljs-number">-99</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; arraySize4D; i++) &#123;<br>        h_xyzside[i] = <span class="hljs-number">0.0f</span>;<br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;arraySize2D;i++)&#123;<br>        h_array2D[i] = <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;arraySize1D;i++)&#123;<br>        h_array1D[i] = <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;arraySize3D;i++)&#123;<br>        h_array1[i] = <span class="hljs-number">0</span>;<br>    &#125;<br>    <br><br><br>    <span class="hljs-comment">// 分配GPU内存</span><br>    <span class="hljs-type">int</span>* d_imark;<br>    <span class="hljs-type">int</span>* d_cut_model;<br>    <span class="hljs-type">int</span>* d_xyzside;<br>    <span class="hljs-type">int</span>* d_counter;<br>    <span class="hljs-type">int</span>* d_array2D;<br>    <span class="hljs-type">int</span>* d_array1D;<br>    <span class="hljs-type">int</span>* d_array1;<br>    <span class="hljs-type">int</span> h_counter = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_array2D,arraySize2D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_array1D,arraySize1D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_array1,arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">hipMalloc</span>(&amp;d_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><br><br>    <span class="hljs-comment">// 将数据从CPU传输到GPU</span><br>    <span class="hljs-built_in">hipMemcpy</span>(d_imark, h_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_cut_model, h_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_xyzside, h_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_array2D,h_array2D,arraySize2D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_array1D,h_array1D,arraySize1D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_array1,h_array1,arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyHostToDevice);<br>    <span class="hljs-built_in">hipMemcpy</span>(d_counter, &amp;h_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyHostToDevice);<br><br>    <span class="hljs-comment">// 定义线程块和网格的大小</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">4</span>)</span></span>;<br>    <span class="hljs-comment">//nx ny nz 数组的大小[nz][ny][nx]</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">blocksPerGrid</span><span class="hljs-params">((nx + threadsPerBlock.x - <span class="hljs-number">1</span>) / threadsPerBlock.x,</span></span><br><span class="hljs-params"><span class="hljs-function">                       (ny + threadsPerBlock.y - <span class="hljs-number">1</span>) / threadsPerBlock.y,</span></span><br><span class="hljs-params"><span class="hljs-function">                       (nz + threadsPerBlock.z - <span class="hljs-number">1</span>) / threadsPerBlock.z)</span></span>;<br><br>    <span class="hljs-comment">// 调用CUDA内核函数</span><br>    <span class="hljs-type">int</span> inter_iL = <span class="hljs-number">4</span>, inter_iR = <span class="hljs-number">13</span> , inter_jL = <span class="hljs-number">4</span>, inter_jR = <span class="hljs-number">13</span>, inter_kL = <span class="hljs-number">4</span>, inter_kR = <span class="hljs-number">18</span>;<br>    processKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_imark, d_cut_model, d_xyzside,d_array1D,d_array2D, d_array1,nx, ny, nz, w, <br>                                                      inter_iL, inter_iR, inter_jL, inter_jR, inter_kL, inter_kR, d_counter);<br><br>    <span class="hljs-comment">// 等待GPU完成</span><br>    <span class="hljs-built_in">hipDeviceSynchronize</span>();<br><br>    <span class="hljs-comment">// 将结果从GPU传回CPU</span><br>    <span class="hljs-built_in">hipMemcpy</span>(h_imark, d_imark, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_cut_model, d_cut_model, arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_xyzside, d_xyzside, arraySize4D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_array2D,d_array2D,arraySize2D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_array2D,d_array2D,arraySize2D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(h_array1,d_array1,arraySize3D * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyDeviceToHost);<br>    <span class="hljs-built_in">hipMemcpy</span>(&amp;h_counter, d_counter, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), hipMemcpyDeviceToHost);<br><br>    <span class="hljs-comment">// 检查计数器</span><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Total elements processed: &quot;</span> &lt;&lt; h_counter &lt;&lt; std::endl;<br><br>    <span class="hljs-comment">// 打印结果（如果需要）</span><br>    <span class="hljs-comment">/*for (int i = 0; i &lt; arraySize3D; i++) &#123;</span><br><span class="hljs-comment">        std::cout &lt;&lt; h_imark[i] &lt;&lt; &quot; &quot;;</span><br><span class="hljs-comment">    &#125;*/</span><br>   <span class="hljs-comment">//只打印被改过的数据1500个</span><br>   <span class="hljs-comment">/*</span><br><span class="hljs-comment">   int sum = 0;</span><br><span class="hljs-comment">    for(int k = inter_kL;k&lt;=inter_kR;k++)&#123;</span><br><span class="hljs-comment">        for(int j = inter_jL;j&lt;=inter_jR;j++)&#123;</span><br><span class="hljs-comment">            for(int i = inter_iL;i&lt;=inter_iR;i++)&#123;               </span><br><span class="hljs-comment">                printf(&quot;%d&quot;,h_imark[k*(ny*nx)+j*nx+i]);</span><br><span class="hljs-comment">                sum++;</span><br><span class="hljs-comment">            &#125;</span><br><span class="hljs-comment">        &#125;</span><br><span class="hljs-comment">    &#125;</span><br><span class="hljs-comment">    printf(&quot;\n&quot;);</span><br><span class="hljs-comment">    printf(&quot;sum = %d&quot;,sum);*/</span><br><br>    std::cout &lt;&lt; std::endl;<br><br>   <span class="hljs-comment">/*for (int i = 0; i &lt; arraySize4D; i++) &#123;</span><br><span class="hljs-comment">        std::cout &lt;&lt; h_xyzside[i] &lt;&lt; &quot; &quot;;</span><br><span class="hljs-comment">    &#125;</span><br><span class="hljs-comment">    std::cout &lt;&lt; std::endl;*/</span><br><br>    <span class="hljs-comment">//只打印被改过的数据1500个</span><br>    <span class="hljs-type">int</span> sum = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = inter_kL;k&lt;=inter_kR;k++)&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = inter_jL;j&lt;=inter_jR;j++)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = inter_iL;i&lt;=inter_iR;i++)&#123;               <br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d,%d,%d\n&quot;</span>,h_xyzside[k * (ny * nx * w) + j * (nx * w) + i * w+<span class="hljs-number">0</span>],h_xyzside[k * (ny * nx * w) + j * (nx * w) + i * w+<span class="hljs-number">1</span>],h_xyzside[k * (ny * nx * w) + j * (nx * w) + i * w+<span class="hljs-number">2</span>]);<br>                sum++;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\n&quot;</span>);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;sum = %d&quot;</span>,sum);<br>    <br><br>    <span class="hljs-comment">/*for(int i = 0;i&lt; arraySize2D;i++)&#123;</span><br><span class="hljs-comment">        std::cout &lt;&lt; h_array2D[i] &lt;&lt; &quot; &quot;;</span><br><span class="hljs-comment">    &#125;</span><br><span class="hljs-comment">    std::cout &lt;&lt; std::endl;</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    for(int i = 0;i&lt; arraySize1D;i++)&#123;</span><br><span class="hljs-comment">        std::cout &lt;&lt; h_array1D[i] &lt;&lt; &quot; &quot;;</span><br><span class="hljs-comment">    &#125;</span><br><span class="hljs-comment">    std::cout &lt;&lt; std::endl;</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    for (int i = 0; i &lt; arraySize3D; i++) &#123;</span><br><span class="hljs-comment">        std::cout &lt;&lt; h_array1[i] &lt;&lt; &quot; &quot;;</span><br><span class="hljs-comment">    &#125;</span><br><span class="hljs-comment">    std::cout &lt;&lt; std::endl;*/</span><br><br><br>    <span class="hljs-comment">// 释放GPU内存</span><br>    <span class="hljs-built_in">hipFree</span>(d_imark);<br>    <span class="hljs-built_in">hipFree</span>(d_cut_model);<br>    <span class="hljs-built_in">hipFree</span>(d_xyzside);<br>    <span class="hljs-built_in">hipFree</span>(d_array2D);<br>    <span class="hljs-built_in">hipFree</span>(d_array1D);<br>    <span class="hljs-built_in">hipFree</span>(d_counter);<br><br>    <span class="hljs-comment">// 释放CPU内存</span><br>    <span class="hljs-keyword">delete</span>[] h_imark;<br>    <span class="hljs-keyword">delete</span>[] h_cut_model;<br>    <span class="hljs-keyword">delete</span>[] h_xyzside;<br>    <span class="hljs-keyword">delete</span>[] h_array1D;<br>    <span class="hljs-keyword">delete</span>[] h_array2D;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><h4 id="先改完，再慢慢测，先测试US然后。。。设置一次迭代"><a href="#先改完，再慢慢测，先测试US然后。。。设置一次迭代" class="headerlink" title="先改完，再慢慢测，先测试US然后。。。设置一次迭代"></a>先改完，再慢慢测，先测试US然后。。。设置一次迭代</h4><p>RK的数组还没改完，测试核函数里面定义的变量，在不同线程中改，会不会混乱。定义的变量存在哪了？</p><p>每个维度的线程索引就对应数组的哪个维度的下标。</p><p>做ppt ？</p><h3 id="CUDA-线程模型"><a href="#CUDA-线程模型" class="headerlink" title="CUDA 线程模型"></a>CUDA 线程模型</h3><ol><li><strong>线程上下文</strong>：<ul><li>每个 CUDA 线程有自己的寄存器和本地内存。</li><li>当你在 <code>__global__</code> 函数中定义一个变量时，例如 <code>int dL;</code>，每个线程都有自己独立的 <code>dL</code> 变量，这些变量存储在线程的寄存器或本地内存中。</li><li>这些变量不会在不同线程之间共享，也不会互相干扰。</li></ul></li><li><strong>块和网格</strong>：<ul><li>CUDA 通过网格（grid）和块（block）来组织线程。</li><li>每个线程都有一个唯一的线程索引（thread index），这可以通过 <code>blockIdx</code> 和 <code>threadIdx</code> 获取。</li><li>基于线程索引，每个线程执行同样的代码，但操作不同的数据。</li></ul></li></ol><h3 id="对不同内存中数组的处理"><a href="#对不同内存中数组的处理" class="headerlink" title="对不同内存中数组的处理"></a>对不同内存中数组的处理</h3><p>从cpu中传入的多维数组，要通过显式数组下标的方式转换为一维数组</p><p>在<code>__global__</code>中定义的多维数组，可以直接访问数组下标，如<code>f[22][5]</code>,</p><p>在<code>__global__</code>中定义的数组和变量是每个线程私有的。在线程之间独立。</p><h3 id="常量传递"><a href="#常量传递" class="headerlink" title="常量传递"></a>常量传递</h3><p>如果要使用 <code>hipMemcpy</code> 函数，你可以用它来传递设备内存中的数据。虽然 <code>hipMemcpy</code> 用于处理普通的设备内存拷贝操作，而 <code>hipMemcpyToSymbol</code> 更适合处理常量内存的拷贝，但如果你希望将数据从主机拷贝到设备内存中的常量区域，<code>hipMemcpyToSymbol</code> 是更合适的方法。</p><h3 id="c转c-注意的问题"><a href="#c转c-注意的问题" class="headerlink" title="c转c++注意的问题"></a>c转c++注意的问题</h3><p>c++函数参数的数组要写成<code>***</code>三维，不要定义数组的大小。</p><p>可能出现的问题，常量到底在哪定义的，main和核函数中都有<code>__constant__</code></p><p>待解决：US,xyz:找不到device函数，找不到Fluidone,但是ASUM能找到Fluidone。device能调用device，写在一块？</p><p>写个测试程序试试能不能调用device函数，使用了分离编译可以了，目前还不能确定行不行。</p><h3 id="分离编译（Separate-Compilation）和链接"><a href="#分离编译（Separate-Compilation）和链接" class="headerlink" title="分离编译（Separate Compilation）和链接"></a>分离编译（Separate Compilation）和链接</h3><p>在 GPU 编程中，尤其是使用 HIP 或 CUDA 时，设备函数（标记为 <code>__device__</code> 的函数）默认情况下只能在同一个编译单元（即同一个源文件）内被调用。这意味着，如果你在一个文件中定义了设备函数，却试图在另一个文件中调用它，编译器会在链接阶段找不到该函数，导致 <strong>undefined symbol</strong> 错误。</p><h4 id="启用分离编译"><a href="#启用分离编译" class="headerlink" title="启用分离编译"></a>启用分离编译</h4><p>通过启用分离编译，编译器能够生成适用于多编译单元的设备代码。分离编译允许你：</p><ul><li>将设备代码分开编译，然后在链接阶段合并。</li><li>在不同的源文件中定义和调用设备函数。</li></ul><h4 id="编译和链接的步骤"><a href="#编译和链接的步骤" class="headerlink" title="编译和链接的步骤"></a>编译和链接的步骤</h4><p>在你的情况下，通过使用 <code>-fgpu-rdc</code> 选项，可以解决 undefined symbol 错误：</p><ol><li><p><strong>编译每个源文件为目标文件</strong></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">bash<br>复制代码<br>hipcc -fgpu-rdc -c fun_dev2<span class="hljs-selector-class">.cu</span> -o fun_dev2<span class="hljs-selector-class">.o</span><br>hipcc -fgpu-rdc -c test2<span class="hljs-selector-class">.cpp</span> -o test2.o<br></code></pre></td></tr></table></figure><ul><li>这里的 <code>-fgpu-rdc</code> 告诉编译器为分离编译生成设备代码。</li></ul></li><li><p><strong>链接所有目标文件</strong></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">bash<br>复制代码<br>hipcc -fgpu-rdc test2<span class="hljs-selector-class">.o</span> fun_dev2<span class="hljs-selector-class">.o</span> -o test<br></code></pre></td></tr></table></figure><ul><li>在链接阶段，同样使用 <code>-fgpu-rdc</code> 选项，以确保链接器能够解析所有设备函数调用。</li></ul></li></ol><p><img src="/../images/1721914186493.png" alt="1721914186493"></p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>c转hipc</title>
    <link href="/2024/07/09/cTohipc/"/>
    <url>/2024/07/09/cTohipc/</url>
    
    <content type="html"><![CDATA[<h1 id="c转hipc"><a href="#c转hipc" class="headerlink" title="c转hipc"></a>c转hipc</h1><p>cuda 类比 hip</p><p>如果您将 <code>add</code> 和 <code>myKernel</code> 函数分别写在不同的文件中，并希望在主函数中调用 <code>myKernel</code> 函数，需要进行以下步骤：</p><ol><li><p><strong>定义 add 函数的头文件</strong>：创建一个头文件（例如 <code>cuda_functions.h</code>），在其中声明 <code>add</code> 函数为 <code>__device__</code> 函数。myKernel函数为<code>__global__</code>函数</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cpp<br><span class="hljs-comment">// cuda_functions.h</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> CUDA_FUNCTIONS_H</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CUDA_FUNCTIONS_H</span><br><br><span class="hljs-function">__device__ <span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span></span>;<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">myKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *array, <span class="hljs-type">int</span> N)</span></span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span> <span class="hljs-comment">// CUDA_FUNCTIONS_H</span></span><br></code></pre></td></tr></table></figure></li><li><p><strong>实现 add 函数的源文件</strong>：创建一个源文件（例如 <code>cuda_functions.cu</code>），在其中定义 <code>add</code> 函数的实现。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cpp<br><span class="hljs-comment">// cuda_functions.cu</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_functions.h&quot;</span></span><br><br><span class="hljs-function">__device__ <span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> a + b;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>定义 myKernel 函数的源文件</strong>：创建另一个源文件（例如 <code>my_kernel.cu</code>），在其中定义 <code>myKernel</code> 函数。</p><figure class="highlight stan"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stan">cpp<br><span class="hljs-comment">// my_kernel.cu</span><br><br><span class="hljs-meta">#include &quot;<span class="hljs-string">cuda_functions.h</span>&quot;</span><br><br>__global__ <span class="hljs-type">void</span> myKernel(<span class="hljs-type">int</span> *<span class="hljs-type">array</span>, <span class="hljs-type">int</span> N) &#123;<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-keyword">if</span> (idx &lt; N) &#123;<br>        <span class="hljs-comment">// 调用子函数</span><br>        <span class="hljs-type">array</span>[idx] = add(<span class="hljs-type">array</span>[idx], <span class="hljs-number">5</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>主函数中的调用</strong>：在主函数中包含头文件 <code>cuda_functions.h</code>，并调用 <code>myKernel</code> 函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cpp<br><span class="hljs-comment">// main.cpp</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_functions.h&quot;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">10</span>;<br>    <span class="hljs-type">int</span> array[N];<br><br>    <span class="hljs-type">int</span> *d_array;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span> **)&amp;d_array, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_array, array, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), cudaMemcpyHostToDevice);<br><br>    <span class="hljs-type">int</span> blockSize = <span class="hljs-number">256</span>;<br>    <span class="hljs-type">int</span> numBlocks = (N + blockSize - <span class="hljs-number">1</span>) / blockSize;<br>    myKernel&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(d_array, N);<br><br>    <span class="hljs-built_in">cudaMemcpy</span>(array, d_array, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), cudaMemcpyDeviceToHost);<br><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Modified array:&quot;</span> &lt;&lt; std::endl;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; ++i) &#123;<br>        std::cout &lt;&lt; array[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br><br>    <span class="hljs-built_in">cudaFree</span>(d_array);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>编译</strong>：在编译时，需要将所有 <code>.cu</code> 文件都传递给CUDA编译器 <code>nvcc</code>，并链接相应的CUDA库。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">nvcc -o my_program <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.cpp</span> cuda_functions<span class="hljs-selector-class">.cu</span> my_kernel.cu<br></code></pre></td></tr></table></figure></li></ol><p>通过这样的方式，您可以将 CUDA 核函数和其它设备函数分别放置在不同的文件中，并在主函数中正确地调用和使用它们。</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gemm优化（代码实现）</title>
    <link href="/2024/07/07/gemm%E4%BC%98%E5%8C%96_%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <url>/2024/07/07/gemm%E4%BC%98%E5%8C%96_%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="1-参考资料"><a href="#1-参考资料" class="headerlink" title="1 参考资料"></a>1 参考资料</h2><p><a href="https://zhuanlan.zhihu.com/p/442930482">深入浅出GPU优化系列：GEMM优化（二） - 知乎 (zhihu.com)</a></p><p>代码：</p><p><a href="https://github.com/Liu-xiandong/How_to_optimize_in_GPU/tree/master/sgemm">How_to_optimize_in_GPU&#x2F;sgemm at master · Liu-xiandong&#x2F;How_to_optimize_in_GPU (github.com)</a></p><h2 id="2-1-参数说明"><a href="#2-1-参数说明" class="headerlink" title="2.1 参数说明"></a>2.1 参数说明</h2><p>模板参数是GEMM性能调优的关键。不同参数对GEMM性能的影响很大。以下是主要模板参数的说明：</p><ul><li><code>BLOCK_SIZE_M</code>: 每个块计算的C矩阵的高度。</li><li><code>BLOCK_SIZE_K</code>: 每个块从A矩阵加载到共享内存的宽度。</li><li><code>BLOCK_SIZE_N</code>: 每个块计算的C矩阵的宽度。</li><li><code>THREAD_SIZE_Y</code>: 每个线程计算的C矩阵的高度。</li><li><code>THREAD_SIZE_X</code>: 每个线程计算的C矩阵的宽度。</li><li><code>ENABLE_DOUBLE_BUFFER</code>: 是否启用双缓冲（数据预取）。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> BLOCK_SIZE_M,<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> BLOCK_SIZE_K,<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> BLOCK_SIZE_N,<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_SIZE_Y,<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_SIZE_X,<br>    <span class="hljs-type">const</span> <span class="hljs-type">bool</span> ENABLE_DOUBLE_BUFFER<br>    &gt;<br></code></pre></td></tr></table></figure><p>接下来是线程的相关参数。256个block按照二维形态排布，每个block中有256个线程，同样以二维形态排布。以下是主要线程参数的说明：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Block index</span><br><span class="hljs-type">int</span> bx = blockIdx.x;<br><span class="hljs-type">int</span> by = blockIdx.y;<br><br><span class="hljs-comment">// Thread index</span><br><span class="hljs-type">int</span> tx = threadIdx.x;<br><span class="hljs-type">int</span> ty = threadIdx.y;<br><br><span class="hljs-comment">// the threads number in Block of X,Y</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_X_PER_BLOCK = BLOCK_SIZE_N / THREAD_SIZE_X;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_Y_PER_BLOCK = BLOCK_SIZE_M / THREAD_SIZE_Y;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_NUM_PER_BLOCK = THREAD_X_PER_BLOCK * THREAD_Y_PER_BLOCK;<br><br><span class="hljs-comment">// thread id in cur Block</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> tid = ty * THREAD_X_PER_BLOCK + tx;<br></code></pre></td></tr></table></figure><p>在global memory到shared memory的数据搬运中，还需要经过寄存器。以下是一些共享内存和寄存器的分配说明：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// shared memory</span><br>__shared__ <span class="hljs-type">float</span> As[<span class="hljs-number">2</span>][BLOCK_SIZE_K][BLOCK_SIZE_M];<br>__shared__ <span class="hljs-type">float</span> Bs[<span class="hljs-number">2</span>][BLOCK_SIZE_K][BLOCK_SIZE_N];<br><span class="hljs-comment">// registers for C</span><br><span class="hljs-type">float</span> accum[THREAD_SIZE_Y][THREAD_SIZE_X] = &#123;<span class="hljs-number">0</span>&#125;;<br><span class="hljs-comment">// registers for A and B</span><br><span class="hljs-comment">//计算时用到的寄存器，存储每一轮小迭代存储的数据</span><br><span class="hljs-type">float</span> frag_a[<span class="hljs-number">2</span>][THREAD_SIZE_Y];<br><span class="hljs-type">float</span> frag_b[<span class="hljs-number">2</span>][THREAD_SIZE_X];<br><span class="hljs-comment">// registers load global memory</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> ldg_num_a = BLOCK_SIZE_M * BLOCK_SIZE_K / (THREAD_NUM_PER_BLOCK * <span class="hljs-number">4</span>);<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> ldg_num_b = BLOCK_SIZE_K * BLOCK_SIZE_N / (THREAD_NUM_PER_BLOCK * <span class="hljs-number">4</span>);<br><span class="hljs-comment">//从global mem &gt; share mem 中间需要的寄存器</span><br><span class="hljs-type">float</span> ldg_a_reg[<span class="hljs-number">4</span>*ldg_num_a];<br><span class="hljs-type">float</span> ldg_b_reg[<span class="hljs-number">4</span>*ldg_num_b];<br></code></pre></td></tr></table></figure><p>为了优化内存访问，我们定义了一些宏：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> OFFSET(row, col, ld) ((row) * (ld) + (col))</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> FETCH_FLOAT4(pointer) (reinterpret_cast<span class="hljs-string">&lt;float4*&gt;</span>(&amp;(pointer))[0])</span><br></code></pre></td></tr></table></figure><p><strong>define OFFSET(row, col, ld) ((row) * (ld) + (col)):</strong></p><p>该宏用于计算二维数组在一维内存中的偏移量。</p><p><strong>#define FETCH_FLOAT4(pointer) (reinterpret_cast&lt;float4*&gt;(&amp;(pointer))[0])</strong></p><p>该宏用于一次性读取4个连续的<code>float</code>数据。</p><p><strong>解释</strong></p><ul><li>&amp;(pointer)：获取pointer的地址。</li><li><code>reinterpret_cast&lt;float4*&gt;(&amp;(pointer))</code>：将<code>pointer</code>的地址强制转换为指向<code>float4</code>类型的指针。<code>float4</code>是CUDA中的一种数据类型，表示包含4个<code>float</code>的向量。</li><li><code>[0]</code>：解引用该指针，获取<code>float4</code>类型的值。</li></ul><p>这实际上是从内存中读取4个连续的<code>float</code>值，并将它们作为一个<code>float4</code>返回。</p><p><strong>举例</strong></p><p>假设我们有一个连续的<code>float</code>数组：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">cpp<br>复制代码<br><span class="hljs-built_in">float</span> A[<span class="hljs-number">8</span>] = &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>&#125;;<br></code></pre></td></tr></table></figure><p>如果我们希望一次性读取前4个值，可以使用该宏：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">cpp<br>复制代码<br><span class="hljs-built_in">float</span>4 f4 = FETCH_FLOAT4(A[<span class="hljs-number">0</span>]);<br><span class="hljs-comment">// 结果是 f4.x = 0.0, f4.y = 1.0, f4.z = 2.0, f4.w = 3.0</span><br></code></pre></td></tr></table></figure><h2 id="2-2-大迭代前预取数据"><a href="#2-2-大迭代前预取数据" class="headerlink" title="2.2 大迭代前预取数据"></a>2.2 大迭代前预取数据</h2><p>迭代前预取数据分为<strong>两个部分</strong>，<strong>第一个部分</strong>是将第一个大迭代的数据从global 预取到shared memroy中。<strong>第二个部分</strong>是将shared memory上的数据预取到寄存器中。</p><p>第一个部分**是将第一个大迭代的数据从global 预取到shared memroy中。</p><p>先来看看<strong>第一个部分</strong>。这里面分别是将第一个大迭代中需要的A、B数据预取到shared memroy中。对于A矩阵而言，这个for循环代表着block中的线程需要搬运多少次才能将globa中的数据放到shared memory中。由于A需要先进行一次转置，所以先将数据先放置在寄存器中。数据按行取，然后按列存。对于B矩阵而言，数据不用转置，直接按行取，按行存。当然，这个过程中间也要经过寄存器，但是没有写出来的必要了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// load A from global memory to shared memory</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_M; i += A_TILE_ROW_STRIDE) &#123;<br>    <span class="hljs-type">int</span> ldg_index = i / A_TILE_ROW_STRIDE * <span class="hljs-number">4</span>;<br>    <span class="hljs-comment">//先将一个大迭代的数据读取到global mem &gt; shread mem 中间的寄存器中</span><br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(ldg_a_reg[ldg_index]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(A[<span class="hljs-built_in">OFFSET</span>(<br>        BLOCK_SIZE_M * by + A_TILE_ROW_START + i, <span class="hljs-comment">// row</span><br>        A_TILE_COL, <span class="hljs-comment">// col</span><br>        K )]);<br>    <span class="hljs-comment">//再将寄存器的数据读取到shared mem 中，这样就完成了第一次大迭代的数据预取</span><br>    As[<span class="hljs-number">0</span>][A_TILE_COL][A_TILE_ROW_START + i]=ldg_a_reg[ldg_index];<br>    As[<span class="hljs-number">0</span>][A_TILE_COL+<span class="hljs-number">1</span>][A_TILE_ROW_START + i]=ldg_a_reg[ldg_index+<span class="hljs-number">1</span>];<br>    As[<span class="hljs-number">0</span>][A_TILE_COL+<span class="hljs-number">2</span>][A_TILE_ROW_START + i]=ldg_a_reg[ldg_index+<span class="hljs-number">2</span>];<br>    As[<span class="hljs-number">0</span>][A_TILE_COL+<span class="hljs-number">3</span>][A_TILE_ROW_START + i]=ldg_a_reg[ldg_index+<span class="hljs-number">3</span>];<br>&#125;<br><br><span class="hljs-comment">// load B from global memory to shared memory</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_K; i += B_TILE_ROW_STRIDE) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[<span class="hljs-number">0</span>][B_TILE_ROW_START + i][B_TILE_COL]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(B[<span class="hljs-built_in">OFFSET</span>(<br>        B_TILE_ROW_START + i, <span class="hljs-comment">// row</span><br>        B_TILE_COL + BLOCK_SIZE_N * bx, <span class="hljs-comment">// col</span><br>        N )]);<br>&#125;<br>__syncthreads();<br></code></pre></td></tr></table></figure><p>第二个部分**是将shared memory上的数据预取到寄存器中</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// load A from shared memory to register</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; thread_y += <span class="hljs-number">4</span>) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_a[<span class="hljs-number">0</span>][thread_y]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(As[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][THREAD_SIZE_Y * ty + thread_y]);<br>&#125;<br><br><span class="hljs-comment">// load B from shared memory to register</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; thread_x += <span class="hljs-number">4</span>) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_b[<span class="hljs-number">0</span>][thread_x]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][THREAD_SIZE_X * tx + thread_x]);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-3-大迭代逻辑"><a href="#2-3-大迭代逻辑" class="headerlink" title="2.3 大迭代逻辑"></a>2.3 大迭代逻辑</h2><p>每个大迭代加载新的数据块，并执行一系列的小迭代。我们先设置一些参数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> write_stage_idx = <span class="hljs-number">1</span>;<br><span class="hljs-type">int</span> tile_idx = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">do</span> &#123;<br>    tile_idx += BLOCK_SIZE_K;<br>    <span class="hljs-type">int</span> load_stage_idx = write_stage_idx ^ <span class="hljs-number">1</span>;<br>    <span class="hljs-comment">// compute</span><br>    <span class="hljs-keyword">if</span> (tile_idx &lt; K) &#123;<br>        write_stage_idx ^= <span class="hljs-number">1</span>;<br>    &#125;<br>&#125; <span class="hljs-keyword">while</span> (tile_idx &lt; K);<br></code></pre></td></tr></table></figure><h2 id="2-4-大迭代详细解析"><a href="#2-4-大迭代详细解析" class="headerlink" title="2.4 大迭代详细解析"></a>2.4 大迭代详细解析</h2><h3 id="1-在大迭代中，我们将global-memory的数据块搬运到中间寄存器："><a href="#1-在大迭代中，我们将global-memory的数据块搬运到中间寄存器：" class="headerlink" title="1.在大迭代中，我们将global memory的数据块搬运到中间寄存器："></a>1.在大迭代中，我们将global memory的数据块搬运到中间寄存器：</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++">tile_idx += BLOCK_SIZE_K;<br><span class="hljs-keyword">if</span> (tile_idx &lt; K) &#123;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_M; i += A_TILE_ROW_STRIDE) &#123;<br>        <span class="hljs-type">int</span> ldg_index = i / A_TILE_ROW_STRIDE * <span class="hljs-number">4</span>;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(ldg_a_reg[ldg_index]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(A[<span class="hljs-built_in">OFFSET</span>(<br>            BLOCK_SIZE_M * by + A_TILE_ROW_START + i, <span class="hljs-comment">// row</span><br>            A_TILE_COL + tile_idx, <span class="hljs-comment">// col</span><br>            K )]);<br>    &#125;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_K; i += B_TILE_ROW_STRIDE) &#123;<br>        <span class="hljs-type">int</span> ldg_index = i / A_TILE_ROW_STRIDE * <span class="hljs-number">4</span>;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(ldg_b_reg[ldg_index]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(B[<span class="hljs-built_in">OFFSET</span>(<br>            tile_idx + B_TILE_ROW_START + i, <span class="hljs-comment">// row</span><br>            B_TILE_COL + BLOCK_SIZE_N * bx, <span class="hljs-comment">// col</span><br>            N )]);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-进入小迭代的计算逻辑：将shared-mem-的数据存储到寄存器中"><a href="#2-进入小迭代的计算逻辑：将shared-mem-的数据存储到寄存器中" class="headerlink" title="2.进入小迭代的计算逻辑：将shared mem 的数据存储到寄存器中"></a>2.进入小迭代的计算逻辑：将shared mem 的数据存储到寄存器中</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> load_stage_idx = write_stage_idx ^ <span class="hljs-number">1</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; BLOCK_SIZE_K - <span class="hljs-number">1</span>; ++j) &#123;<br>    <span class="hljs-comment">// load next tile from shared mem to register </span><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; thread_y += <span class="hljs-number">4</span>) &#123;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_a[(j + <span class="hljs-number">1</span>) % <span class="hljs-number">2</span>][thread_y]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(As[load_stage_idx][j + <span class="hljs-number">1</span>][THREAD_SIZE_Y * ty + thread_y]);<br>    &#125;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; thread_x += <span class="hljs-number">4</span>) &#123;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_b[(j + <span class="hljs-number">1</span>) % <span class="hljs-number">2</span>][thread_x]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[load_stage_idx][j + <span class="hljs-number">1</span>][THREAD_SIZE_X * tx + thread_x]);<br>    &#125;<br>    <span class="hljs-comment">// compute C THREAD_SIZE_X x THREAD_SIZE_Y</span><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; ++thread_y) &#123;<br>        <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; ++thread_x) &#123;<br>            accum[thread_y][thread_x] += frag_a[j % <span class="hljs-number">2</span>][thread_y] * frag_b[j % <span class="hljs-number">2</span>][thread_x];<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-将数据从寄存器搬运到shared-memory："><a href="#3-将数据从寄存器搬运到shared-memory：" class="headerlink" title="3.将数据从寄存器搬运到shared memory："></a>3.将数据从寄存器搬运到shared memory：</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">if</span> (tile_idx &lt; K) &#123;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_M; i += A_TILE_ROW_STRIDE) &#123;<br>        <span class="hljs-type">int</span> ldg_index = i / A_TILE_ROW_STRIDE * <span class="hljs-number">4</span>;<br>        As[write_stage_idx][A_TILE_COL][A_TILE_ROW_START + i] = ldg_a_reg[ldg_index];<br>        As[write_stage_idx][A_TILE_COL + <span class="hljs-number">1</span>][A_TILE_ROW_START + i] = ldg_a_reg[ldg_index + <span class="hljs-number">1</span>];<br>        As[write_stage_idx][A_TILE_COL + <span class="hljs-number">2</span>][A_TILE_ROW_START + i] = ldg_a_reg[ldg_index + <span class="hljs-number">2</span>];<br>        As[write_stage_idx][A_TILE_COL + <span class="hljs-number">3</span>][A_TILE_ROW_START + i] = ldg_a_reg[ldg_index + <span class="hljs-number">3</span>];<br>    &#125;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_K; i += B_TILE_ROW_STRIDE) &#123;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[write_stage_idx][B_TILE_ROW_START + i][B_TILE_COL]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(ldg_b_reg[ldg_index]);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-最后，将shared-memory的数据块加载到寄存器，完成寄存器的预取，并将最后一个小迭代完成"><a href="#4-最后，将shared-memory的数据块加载到寄存器，完成寄存器的预取，并将最后一个小迭代完成" class="headerlink" title="4.最后，将shared memory的数据块加载到寄存器，完成寄存器的预取，并将最后一个小迭代完成"></a>4.最后，将shared memory的数据块加载到寄存器，完成寄存器的预取，并将最后一个小迭代完成</h3><p>“最后一个小迭代？”是为了处理前七次迭代没有处理过的最后的一部分矩阵相乘。“最后完成寄存器的预取”这一部分是为下一次大迭代的第一次小迭代进行预取，不是为了本次大迭代的最后一次小迭代预取。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// load A from shared memory to register</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; thread_y += <span class="hljs-number">4</span>) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_a[<span class="hljs-number">0</span>][thread_y]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(As[write_stage_idx][<span class="hljs-number">0</span>][THREAD_SIZE_Y * ty + thread_y]);<br>&#125;<br><span class="hljs-comment">// load B from shared memory to register</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; thread_x += <span class="hljs-number">4</span>) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_b[<span class="hljs-number">0</span>][thread_x]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[write_stage_idx][<span class="hljs-number">0</span>][THREAD_SIZE_X * tx + thread_x]);<br>&#125;<br><span class="hljs-comment">//compute last tile mma THREAD_SIZE_X x THREAD_SIZE_Y</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; ++thread_y) &#123;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; ++thread_x) &#123;<br>        accum[thread_y][thread_x] += frag_a[<span class="hljs-number">1</span>][thread_y] * frag_b[<span class="hljs-number">1</span>][thread_x];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="5-计算结果写回"><a href="#5-计算结果写回" class="headerlink" title="5.计算结果写回"></a>5.计算结果写回</h3><p>此时，最后的计算结果已经被存储在<code>accum</code>寄存器中，需要将其写回到global memory中。这个代码比较简单，就没啥好说的了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// store back to C</span><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; ++thread_y) &#123;<br>        <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; thread_x+=<span class="hljs-number">4</span>) &#123;<br>            <span class="hljs-built_in">FETCH_FLOAT4</span>(C[<span class="hljs-built_in">OFFSET</span>(<br>                BLOCK_SIZE_M * by + ty * THREAD_SIZE_Y + thread_y,<br>                BLOCK_SIZE_N * bx + tx * THREAD_SIZE_X + thread_x,<br>                N)]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(accum[thread_y][thread_x]);<br>        &#125;<br>    &#125;<br></code></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过采用数据预取和双缓冲技术，我们可以大大提高GEMM的计算效率。这种方法确保了在大部分计算过程中，计算单元都在忙碌地进行计算，而不是在等待数据传输。这种优化方法在大型矩阵乘法中尤其有效。</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>纪念</title>
    <link href="/2024/07/03/%E7%BA%AA%E5%BF%B5/"/>
    <url>/2024/07/03/%E7%BA%AA%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<p>今天没开组会，结束了一轮的训练</p><p>找到了很好看的美剧，无耻之徒</p><p>明天是我的生日，有谁会记得呢？</p><p>23岁结束，24岁，加油</p><p>明天下雨，早上好好睡觉吧，休息一下吧，晚上吃点好的。</p><p><img src="/../images/1720012074393.png" alt="1720012074393"></p><p>尺度有点大</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>日记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gemm优化</title>
    <link href="/2024/07/02/gemm%E4%BC%98%E5%8C%96/"/>
    <url>/2024/07/02/gemm%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="Gemm-优化"><a href="#Gemm-优化" class="headerlink" title="Gemm 优化"></a>Gemm 优化</h1><p><strong>参考资料</strong></p><p><a href="https://zhuanlan.zhihu.com/p/435908830">深入浅出GPU优化系列：GEMM优化（一） - 知乎 (zhihu.com)</a></p><h2 id="整体思路"><a href="#整体思路" class="headerlink" title="整体思路"></a>整体思路</h2><h3 id="分块"><a href="#分块" class="headerlink" title="分块"></a>分块</h3><p><strong>分块是针对整个问题，先成条，即每个block，再分成block的每一次大迭代，再分成大迭代中的每次小迭代。</strong></p><p><strong>先分成条（block），再分成更小的条（大迭代），再分。</strong></p><p>取bm&#x3D;128,bn&#x3D;128,bk&#x3D;8,rm&#x3D;8,rn&#x3D;8</p><p>A，B，C，其维度都是2048×2048</p><p>要求解C&#x3D;A×B。那么我们需要开启（2048&#x2F;128）×（2048&#x2F;128）&#x3D;<strong>256个block</strong>，</p><p>每个block里面有（128&#x2F;8）×（128&#x2F;8）&#x3D;<strong>256个线程</strong>，</p><p>每个线程需要负责计算C矩阵中8×8&#x3D;64个元素的结果，每个block负责256×64&#x3D;16384个元素的结果。</p><p><img src="/../images/1719926905491.png" alt="1719926905491"></p><p>一个block算的是，128 × 2048 ，2048 × 128 ，大长条（block）。</p><p><img src="/../images/1719927479717.png" alt="1719927479717"></p><p><img src="/../images/1719927489368.png" alt="1719927489368"></p><p>block中有K次大迭代，K&#x3D; k&#x2F;bk&#x3D;2048&#x2F;8 &#x3D; 256，一次大迭代算的是128 × 8     8 × 128</p><p>小条（大迭代）</p><p><img src="/../images/1719927530708.png" alt="1719927530708"></p><p><img src="/../images/1719927534500.png" alt="1719927534500"></p><p>bk &#x3D; 8 每个线程有8次小迭代，一次小迭代算的是 8 × 1   1 × 8</p><p>更小的条（小迭代），把上面的图放大</p><p><img src="/../images/1719927620368.png" alt="1719927620368"></p><h3 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h3><p><strong>迭代是针对一个block进行的，每一个block都要进行256次大迭代，每个大迭代里面又有8个小迭代</strong></p><p><strong>即：写代码的逻辑</strong></p><p>明确了上面的参数之后，我们来仔细地观察其中<strong>一个block</strong>的计算逻辑。对于这个block而言，它需要进行2048&#x2F;8&#x3D;256次迭代，我们先把这个迭代称为<strong>大迭代</strong>，每一次大迭代都需要把A里面128×8&#x3D;1024个元素和B里面8×128&#x3D;1024个元素先放到shared memory中。然后这个block中的256个线程把结果计算出来。计算完之后，再进入下一次大迭代。不断重复该过程，直至这个block负责的16384个元素的结果被求解出。大迭代示意图如下：</p><p><img src="/../images/1719926415038.png" alt="1719926415038"></p><p>随后再具体看看每一个大迭代中，block中的线程的计算逻辑。在进行一个大迭代时，shared memory中有128×8&#x3D;1024个A矩阵元素和8×128&#x3D;1024个B矩阵元素。随后，每个线程需要进行8次迭代，我们把这个迭代成为<strong>小迭代</strong>。bk&#x3D;8，所以有8次小迭代。每一次小迭代中，每个线程需要从shared memory中拿到A矩阵的一小列和B矩阵的一小行，即8个A的元素和8个B的元素。线程将这8+8&#x3D;16个元素放置在寄存器中。每个线程需要负责8×8&#x3D;64个元素的计算，一共会产生64条FFMA指令。小迭代示意图如下：</p><p><img src="/../images/1719926427313.png" alt="1719926427313"></p><p>总的来说，<strong>对于一个block而言，有256个大迭代，每个大迭代中又有8个小迭代</strong></p><p>总之很绕，看了好久，脑子里有个模糊的概念了。然后看代码的实现吧，明天开组会讲点啥呢？</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gemm+im2col</title>
    <link href="/2024/07/01/gemm_im2col/"/>
    <url>/2024/07/01/gemm_im2col/</url>
    
    <content type="html"><![CDATA[<h2 id="gemm-im2col"><a href="#gemm-im2col" class="headerlink" title="gemm+im2col"></a>gemm+im2col</h2><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://blog.csdn.net/taoqick/article/details/129051936">高性能卷积计算：img2col 原理详解-CSDN博客</a></p><p><a href="https://seanwangjs.github.io/2022/04/28/im2col-programming.html">使用 C++ 实现 im2col 操作 - Fenrier Lab (seanwangjs.github.io)</a></p><h3 id="im2col"><a href="#im2col" class="headerlink" title="im2col"></a>im2col</h3><p>img2col 是一种实现卷积操作的加速计算策略。它能将卷积操作转化为 GEMM，从而最大化地缩短卷积计算的时间。</p><h4 id="为什么要将卷积操作转化为-GEMM-呢？"><a href="#为什么要将卷积操作转化为-GEMM-呢？" class="headerlink" title="为什么要将卷积操作转化为 GEMM 呢？"></a><strong>为什么要将卷积操作转化为 GEMM 呢？</strong></h4><p>1.因为线性代数领域已经有非常成熟的计算接口（BLAS，Fortran 语言实现）来高效地实现大型的矩阵乘法，几乎可以做到极限优化。</p><p>2.将卷积过程中用到的所有特征子矩阵整合成一个大型矩阵存放在连续的内存中，虽然增加了存储成本，但是减少了内存访问的次数，从而缩短了计算时间。</p><h4 id="img2col将卷积操作转化为GEMM过程"><a href="#img2col将卷积操作转化为GEMM过程" class="headerlink" title="img2col将卷积操作转化为GEMM过程"></a>img2col将卷积操作转化为GEMM过程</h4><p><img src="/../images/1719824785939.png" alt="1719824785939"></p><h5 id="1-Input-Features-Input-Matrix"><a href="#1-Input-Features-Input-Matrix" class="headerlink" title="1.Input Features &gt; Input Matrix"></a>1.Input Features &gt; Input Matrix</h5><p><img src="/../images/1719824926813.png" alt="1719824926813"></p><p>输入特征图有三个通道，用三个不同的颜色来表示</p><p>因为卷积核的大小为2乘2，当卷积核的滑动步长为1的时候，那么传统的直接卷积计算一共需要进行 4 次卷积核与对应特征子矩阵之间的点积运算。</p><p>现在把每一个子矩阵都排列成一个行向量，就得到了三个通道的特征图对应的三个矩阵（Input Matrix）</p><h5 id="2-Convolution-Kernel-Kernel-Matrix"><a href="#2-Convolution-Kernel-Kernel-Matrix" class="headerlink" title="2.Convolution Kernel &gt; Kernel Matrix"></a>2.Convolution Kernel &gt; Kernel Matrix</h5><p><img src="/../images/1719825159189.png" alt="1719825159189"></p><p>卷积核有两个，每一个也是三通道的，我们研究其中一个卷积核</p><p>将卷积核转换为列向量，然后再把每一个通道对应的 Kernel Matrix 堆叠成一个完整的 Kernel Matrix。</p><h5 id="3-Input-Matrix-Kernel-Matrix-Output-Matrix"><a href="#3-Input-Matrix-Kernel-Matrix-Output-Matrix" class="headerlink" title="3.Input Matrix * Kernel Matrix &#x3D; Output Matrix"></a>3.Input Matrix * Kernel Matrix &#x3D; Output Matrix</h5><p>调用GEMM接口，将两个矩阵进行乘积。然后将输出矩阵通过 col2img 函数就可以得到和卷积运算一样的输出特征图。</p><p><img src="/../images/1719825458677.png" alt="1719825458677"></p><h4 id="c-代码实现im2col"><a href="#c-代码实现im2col" class="headerlink" title="c++代码实现im2col"></a>c++代码实现im2col</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">im2col</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span>* data_im, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> im_c, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> im_w, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> im_h, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> kw, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> kh, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> ph, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> pw, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> sh,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> sw,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">float</span>* data_col, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> col_w, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> col_h)</span> </span>&#123;<br><br>        <span class="hljs-comment">// win_w and win_h are the stop times of the kernel in the image.</span><br>        <span class="hljs-type">int</span> win_w = (im_w + <span class="hljs-number">2</span> * pw - kw + <span class="hljs-number">1</span>) / sw;<br>        <span class="hljs-type">int</span> win_h = (im_h + <span class="hljs-number">2</span> * ph - kh + <span class="hljs-number">1</span>) / sh;<br><br>        <br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i&lt; col_h; i++) &#123;<br><br>            x = i % win_w;<br>            y = i / win_w;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; col_w; j++) &#123;<br>                <span class="hljs-type">int</span> c = j / (kw * kh);<br>                <span class="hljs-type">int</span> kj = j % kw;<br>                <span class="hljs-type">int</span> ki = j / kw;<br><br>                <span class="hljs-type">int</span> row = y * sh + ki;<br>                <span class="hljs-type">int</span> col = x * sw + kj;<br><br>                data_col[i * col_w + j] = <span class="hljs-built_in">get_data</span>(data_im, c, im_w, im_h, row, col, ph, pw);<br>            &#125;<br>        &#125;<br><br>    &#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cublas库 学习</title>
    <link href="/2024/07/01/cublas%E5%BA%93/"/>
    <url>/2024/07/01/cublas%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h2 id="cublas库"><a href="#cublas库" class="headerlink" title="cublas库"></a>cublas库</h2><h3 id="what-is-cublas？"><a href="#what-is-cublas？" class="headerlink" title="what is cublas？"></a>what is cublas？</h3><p>CUDA Basic Linear Algebra Subprograms（BLAS）提供了高效计算线性代数的方法。</p><p>有三级API和cuBLAS 扩展、辅助API：</p><p>最基础操作，例如加、减、最大值、复制、转置<br>矩阵的一般操作，例如特殊类型矩阵的乘法、rank<br>更复杂一些的例子，例如“使用一般矩阵计算批量的矩阵-矩阵乘积”，‘使用高斯复杂度降低算法计算一般矩阵的矩阵-矩阵乘积’<br>API介绍：<a href="https://docs.nvidia.com/cuda/cublas/index.html">https://docs.nvidia.com/cuda/cublas/index.html</a></p><p>样例代码：<a href="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLAS">https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLAS</a></p><p>功能：</p><p>向量和矩阵操作：包括向量加法、向量-标量乘法、向量点积等。<br>矩阵乘法：支持各种形式的矩阵乘法，包括方阵乘法、矩阵-向量乘法等。<br>分解和求逆：例如LU分解、Cholesky分解和矩阵求逆等。<br>求解线性系统：使用不同的方法解决线性方程组。</p><h3 id="实例程序："><a href="#实例程序：" class="headerlink" title="实例程序："></a>实例程序：</h3><p>计算三角带状矩阵向量乘法</p><p><a href="https://blog.csdn.net/prinTao/article/details/135634551">【cuda】六、基础库：cuBLAS入门-CSDN博客</a></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdlib&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vector&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hipblas.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime_api.h&gt;</span></span><br><br><span class="hljs-comment">//#include &lt;hipblas_utils.h&gt;</span><br><br><span class="hljs-keyword">using</span> data_type = <span class="hljs-type">double</span>; <span class="hljs-comment">//数据类型为double</span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc,<span class="hljs-type">char</span> *argv[])</span></span>&#123;<br><span class="hljs-comment">//声明一个hipBLAS句柄</span><br>hipblasHandle_t hipblasH = <span class="hljs-literal">NULL</span>;<br><span class="hljs-comment">//声明一个HIP 流</span><br>hipStream_t stream = <span class="hljs-literal">NULL</span>;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> m = <span class="hljs-number">2</span>;<span class="hljs-comment">//矩阵A的行数</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> n = <span class="hljs-number">2</span>;<span class="hljs-comment">//矩阵A的列数</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> k = <span class="hljs-number">1</span>;<span class="hljs-comment">//定义超对角线元素的个数（用于三角矩阵的函数）</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> lda = m;<span class="hljs-comment">//定义矩阵A的领先维度（leading dimension）</span><br><br><span class="hljs-comment">//初始化矩阵A和向量x</span><br><span class="hljs-comment">//std::vector 是c++标准库中的动态数组类，可以存储动态变化数量的元素</span><br><span class="hljs-type">const</span> std::vector&lt;data_type&gt; A = &#123;<span class="hljs-number">1.0</span>,<span class="hljs-number">3.0</span>,<span class="hljs-number">2.0</span>,<span class="hljs-number">4.0</span>&#125;;<br>std::vector&lt;data_type&gt; x = &#123;<span class="hljs-number">5.0</span>,<span class="hljs-number">6.0</span>&#125;;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> incx = <span class="hljs-number">1</span>;<span class="hljs-comment">//x的步长</span><br><br>data_type *d_A = <span class="hljs-literal">nullptr</span>;<span class="hljs-comment">//设备端的矩阵A</span><br>data_type *d_x = <span class="hljs-literal">nullptr</span>;<span class="hljs-comment">//设备端的向量x</span><br><br><span class="hljs-comment">//hipBLAS的相关设置</span><br>hipblasFillMode_t uplo = HIPBLAS_FILL_MODE_UPPER;<span class="hljs-comment">//使用上三角形式</span><br>hipblasOperation_t transa = HIPBLAS_OP_N;<span class="hljs-comment">//矩阵A不进行转置</span><br>hipblasDiagType_t diag = HIPBLAS_DIAG_NON_UNIT;<span class="hljs-comment">//矩阵A的对角线元素不被视为1</span><br><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;A\n&quot;</span>);<br><span class="hljs-comment">//print_matrix(m,n,A.data(),lda);</span><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;======\n&quot;</span>);<br><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;x\n&quot;</span>);<br><span class="hljs-comment">//print_vector(x.size(),x.data());</span><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;=====\n&quot;</span>);<br><br><span class="hljs-comment">//step1</span><br><span class="hljs-comment">//hipblasCreate(&amp;hipblasH);</span><br><br><br><br><br><br><br><br><span class="hljs-keyword">return</span> EXIT_SUCCESS;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="卡住了，hip和cuda-blas-库不同"><a href="#卡住了，hip和cuda-blas-库不同" class="headerlink" title="卡住了，hip和cuda  blas 库不同"></a>卡住了，hip和cuda  blas 库不同</h3><p>cuda的库#include &lt;cublas_utils.h&gt;在hip中#include &lt;hipblas_utils.h&gt;，不能调用</p><p>所以后面的一些库函数也无法调用。</p><p>cublas:</p><p>API介绍：<a href="https://docs.nvidia.com/cuda/cublas/index.html">https://docs.nvidia.com/cuda/cublas/index.html</a></p><p>样例代码：<a href="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLAS">https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLAS</a></p><p>hipblas:</p><p><a href="https://rocmdocs.amd.com/projects/hipBLAS/en/latest/index.html">hipBLAS documentation — hipBLAS 2.1.0 Documentation (amd.com)</a></p><p>有时间再研究吧。。。。。</p><p>先用cuda试试</p><p>因为比赛是用的dcu卡，要用hip，这个方法以后再研究。</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>reduce优化(补充)</title>
    <link href="/2024/06/30/reduce%E4%BC%98%E5%8C%96(%E8%A1%A5%E5%85%85)/"/>
    <url>/2024/06/30/reduce%E4%BC%98%E5%8C%96(%E8%A1%A5%E5%85%85)/</url>
    
    <content type="html"><![CDATA[<h3 id="优化6：调整Block大小"><a href="#优化6：调整Block大小" class="headerlink" title="优化6：调整Block大小"></a>优化6：调整Block大小</h3><p>保持每个block的线程数不变，一个线程处理一个数据，两个数据，四个数据。处理多少个数据比较合适呢，这个就需要试了，获得最优的NumPerThread取值。每个线程处理数据增大一倍，同时blockPerGrid 就要减少一倍。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce6</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock];<br>        <span class="hljs-comment">// 数组的全局索引也要变</span><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * (blockDim.x * NumPerThread);<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        <span class="hljs-comment">// 累加一个线程处理的数据</span><br>        <span class="hljs-comment">// 一定要加上这句,确保在开始累加数据之前，它的值是 0</span><br>        sdata[tid] = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j&lt;NumPerThread;j++)&#123;<br>                sdata[tid] += d_in[i + blockDim.x * j];<br>        &#125;<br>        __syncthreads();<br><br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">1024</span> &amp;&amp; tid &lt; <span class="hljs-number">512</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">512</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">512</span> &amp;&amp; tid &lt; <span class="hljs-number">256</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">256</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">256</span> &amp;&amp; tid &lt; <span class="hljs-number">128</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">128</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">128</span> &amp;&amp; tid &lt; <span class="hljs-number">64</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">64</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid &lt; <span class="hljs-number">32</span>)&#123;<br>                <span class="hljs-built_in">warpReduce</span>(sdata,tid);<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid == <span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br>&#125;<br><br>reduce6&lt;&lt;&lt;blocksPerGrid/NumPerThread,threadsPerBlock&gt;&gt;&gt;(d_a,d_partial_c);<br></code></pre></td></tr></table></figure><h3 id="优化7：shuffle指令"><a href="#优化7：shuffle指令" class="headerlink" title="优化7：shuffle指令"></a>优化7：shuffle指令</h3><h4 id="shuffle指令"><a href="#shuffle指令" class="headerlink" title="shuffle指令"></a>shuffle指令</h4><p>NV提出了Shuffle指令，对于reduce优化有着非常好的效果。目前绝大多数访存类算子，像是softmax，batch_norm，reduce等，都是用Shuffle实现。所以，在这里谈一下这么把shuffle指令用在reduce优化上。</p><p>Shuffle指令是一组针对warp的指令。Shuffle指令最重要的特性就是<strong>warp内的寄存器可以相互访问</strong>。在没有shuffle指令的时候，各个线程在进行通信时只能通过shared memory来访问彼此的寄存器。而采用了shuffle指令之后，<strong>warp内的线程可以直接对其他线程的寄存器进行访存</strong>。通过这种方式可以减少访存的延时。除此之外，带来的最大好处就是可编程性提高了，在某些场景下，<strong>就不用shared memory</strong>了。毕竟，开发者要自己去控制 shared memory还是挺麻烦的一个事。</p><p>以后有时间再研究</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>reduce逐步优化</title>
    <link href="/2024/06/29/reduce%E4%BC%98%E5%8C%96/"/>
    <url>/2024/06/29/reduce%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h3 id="参考材料"><a href="#参考材料" class="headerlink" title="参考材料"></a>参考材料</h3><p><a href="https://zhuanlan.zhihu.com/p/426978026">深入浅出GPU优化系列：reduce优化 - 知乎 (zhihu.com)</a></p><h3 id="reduce-baseline-算法（基础规约算法）"><a href="#reduce-baseline-算法（基础规约算法）" class="headerlink" title="reduce baseline 算法（基础规约算法）"></a>reduce baseline 算法（基础规约算法）</h3><p>我们让Num_per_block与Thread_per_block一致，即一个线程处理一个数据，每个block设定为256个线程，一个block负责256个数据的reduce工作。</p><p>假设要处理32M（32*1024）个数据，那么需要的block数为 32M&#x2F;256 &#x3D; 128 个block。</p><p>tid代表每个block里面的线程号，i代表原数组的索引号，将原数组的值分配到每个shared memory 中</p><p>sdata[tid] &#x3D; d_in[i]</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime_api.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 32768</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> threadsPerBlock = <span class="hljs-number">256</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> blocksPerGrid = <span class="hljs-number">128</span>;<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce0</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>__shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock];<br><br><span class="hljs-comment">//each thread loads one element form global memory to shared memory</span><br><span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;<br><span class="hljs-type">int</span> tid = threadIdx.x;<br>sdata[tid] = d_in[i];<br>__syncthreads();<br><br><span class="hljs-comment">//do reduction in shared memory</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = <span class="hljs-number">1</span>;s&lt;blockDim.x;s*=<span class="hljs-number">2</span>)&#123;<br><span class="hljs-keyword">if</span>(tid%(<span class="hljs-number">2</span>*s)==<span class="hljs-number">0</span>)&#123;<br>sdata[tid] += sdata[tid+s];<br>&#125;<br>__syncthreads();<br>&#125;<br><br><span class="hljs-comment">//wirte result for this block to global memory</span><br><span class="hljs-keyword">if</span>(tid ==<span class="hljs-number">0</span>)&#123;<br>d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>&#125;<br><br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>&#123;<br><br><span class="hljs-type">int</span> a[N],partial_c[blocksPerGrid];<br><span class="hljs-type">long</span> c;<br><span class="hljs-type">int</span> *d_a,*d_partial_c;<br><span class="hljs-built_in">hipMalloc</span>((<span class="hljs-type">void</span> **)&amp;d_a,N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><span class="hljs-built_in">hipMalloc</span>((<span class="hljs-type">void</span> **)&amp;d_partial_c,blocksPerGrid*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><span class="hljs-comment">//initial</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;N;i++)&#123;<br>a[i] = i;<br>&#125;<br><span class="hljs-built_in">hipMemcpy</span>(d_a,a,N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyHostToDevice);<br>reduce0&lt;&lt;&lt;blocksPerGrid,threadsPerBlock&gt;&gt;&gt;(d_a,d_partial_c);<br><span class="hljs-built_in">hipMemcpy</span>(partial_c,d_partial_c,blocksPerGrid*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyDeviceToHost);<br><br>c = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;blocksPerGrid;i++)&#123;<br>c += partial_c[i];<br>&#125;<br><br><span class="hljs-built_in">hipFree</span>(d_a);<br><span class="hljs-built_in">hipFree</span>(d_partial_c);<br><br><span class="hljs-comment">//check the result</span><br><span class="hljs-keyword">if</span>(c==<span class="hljs-number">32767</span>*<span class="hljs-number">32768</span>/<span class="hljs-number">2</span>)&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;success\n&quot;</span>);<br>&#125;<span class="hljs-keyword">else</span>&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;fail\n&quot;</span>);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;c=%ld&quot;</span>,c);<br>&#125;<br><br><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br><br>&#125;<br><br><br></code></pre></td></tr></table></figure><h3 id="what-is-warp-and-bank"><a href="#what-is-warp-and-bank" class="headerlink" title="what is warp and bank"></a>what is warp and bank</h3><h4 id="warp"><a href="#warp" class="headerlink" title="warp:"></a>warp:</h4><p>并行计算时最小的并发结构，通常由连续32个thread组成,也称线程束。</p><h4 id="bank"><a href="#bank" class="headerlink" title="bank:"></a>bank:</h4><p>是对SM中共享内存的划分，划分个数与对应硬件warp中所含thread数一致。对应使用的计算能力3.x版本的显卡，一个warp含有32个thread，因此划分的bank数也为32，并且每个bank的宽度大小为4bytes，对应于一个int型或float型变量。</p><h3 id="优化1：解决warp-divergence"><a href="#优化1：解决warp-divergence" class="headerlink" title="优化1：解决warp divergence"></a>优化1：解决warp divergence</h3><h4 id="warp-divergence："><a href="#warp-divergence：" class="headerlink" title="warp divergence："></a>warp divergence：</h4><p>对于同一个warp中的所有thread是完全并行的，且必须要执行相同的指令，当同一warp中的thread分配了不同的指令时，会发生warp divergence，增加了程序的运行时间。为了有效地解决上述divergence问题，在分配任务时，尽量的使用索引号连续的thread，使活跃的thread全部集中到某些warp中，避免同一warp中同时存在活跃和不活跃两种状态的thread。</p><p>对于reduce算法问题，如果存在if-else这样的分支情况的话，thread会执行所有的分支。只是不满足条件的分支，所产生的结果不会记录下来。可以在图中看到，在每一轮迭代中都会产生两个分支，分别是红色和橙色的分支。这严重影响了代码执行的效率。其中红色的线程是符合if条件的线程，只有他们需要干活。</p><p><img src="/../images/1719653482706.png" alt="1719653482706"></p><h4 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h4><p>解决的方式也比较明了，就是尽可能地让所有线程走到同一个分支里面。</p><p>虽然代码依旧存在着if语句，但是却与reduce0代码有所不同。我们继续假定block中存在256个thread，即拥有256&#x2F;32&#x3D;8个warp。由于blockDim.x &#x3D; 256。对于3号warp，index &#x3D; 2乘tid&#x3D;2乘4乘32&#x3D;256，正好到第三个warp。当进行<strong>第1次迭代</strong>时，0-3号warp的index&lt;blockDim.x， 4-7号warp的index&gt;&#x3D;blockDim.x。对于每个warp而言，都只是进入到一个分支内，所以并不会存在warp divergence的情况。当进行<strong>第2次迭代</strong>时，0、1号两个warp进入计算分支。当进行<strong>第3次迭代</strong>时，只有0号warp进入计算分支。当进行<strong>第4次迭代</strong>时，只有0号warp的前16个线程进入分支。此时开始产生warp divergence。通过这种方式，我们消除了前3次迭代的warp divergence。</p><p>这样第一轮迭代只有前3个warp里面的连续线程是忙碌的，消除了warp divergence</p><h4 id="优化代码："><a href="#优化代码：" class="headerlink" title="优化代码："></a>优化代码：</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce1</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>__shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock];<br><br><span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;<br><span class="hljs-type">int</span> tid = threadIdx.x;<br>sdata[tid] = d_in[i];<br>__syncthreads();<br><span class="hljs-comment">//do reduction in shared memory</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = <span class="hljs-number">1</span>;s&lt;blockDim.x;s*=<span class="hljs-number">2</span>)&#123;<br><span class="hljs-type">int</span> index = <span class="hljs-number">2</span>*tid*s;<br><span class="hljs-keyword">if</span>(index &lt; blockDim.x)&#123;<br>sdata[index] += sdata[index+s];<br>&#125;<br>__syncthreads();<br>&#125;<br><span class="hljs-comment">//wirte result for this block to global memory</span><br><span class="hljs-keyword">if</span>(tid == <span class="hljs-number">0</span>)&#123;<br>d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="优化2：解决bank冲突"><a href="#优化2：解决bank冲突" class="headerlink" title="优化2：解决bank冲突"></a>优化2：解决bank冲突</h3><h4 id="bank-conflict"><a href="#bank-conflict" class="headerlink" title="bank conflict:"></a>bank conflict:</h4><p> 一个SM中，共享内存会被分成多个bank，共享内存中以每4*32bytes为单位，顺序的存储在bank0~bank31中，当两个不同的thread同时访问同一bank内的值时，会发生bank conflict，也会增加程序运行的时间。</p><h4 id="解决思路-1"><a href="#解决思路-1" class="headerlink" title="解决思路"></a>解决思路</h4><p>reduce1的最大问题是<strong>bank冲突</strong>。我们把目光聚焦在这个for循环中。并且只聚焦在<strong>0号warp</strong>。在<strong>第一次迭代</strong>中，0号线程需要去load shared memory的0号地址以及1号地址的数，然后写回到0号地址。而此时，这个warp中的16号线程，需要去load shared memory中的32号地址和33号地址。可以发现，0号地址跟32号地址产生了<strong>2路的bank冲突</strong>。再往后迭代会出现更多路的bank冲突</p><p>slove：</p><p>在reduce中，解决bank冲突的方式就是把for循环逆着来。原来stride从0到256，现在stride从128到0。</p><p>把目光继续看到这个for循环中，并且只分析0号warp。0号线程需要load shared memory的0号元素以及128号元素。第2轮迭代，0号线程load 0号元素和64号元素，1号线程load 1号元素和65号元素。第3轮迭代，0号线程load 0号元素和32号元素。到了4轮迭代，0号线程load 0号元素和16号元素。15号线程load 15号元素和31号元素。那16号线程呢，16号线程啥也不干，因为s&#x3D;16，16-31号线程啥也不干，跳过去了。</p><h4 id="优化代码"><a href="#优化代码" class="headerlink" title="优化代码"></a>优化代码</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce2</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock];<br><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        sdata[tid] = d_in[i];<br>        __syncthreads();<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = blockDim.x/<span class="hljs-number">2</span>;s&gt;<span class="hljs-number">0</span>;s/=<span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-keyword">if</span>(tid&lt;s)&#123;<br>                        sdata[tid] += sdata[tid+s];<br>                &#125;<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid==<span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="优化3：解决idle线程"><a href="#优化3：解决idle线程" class="headerlink" title="优化3：解决idle线程"></a>优化3：解决idle线程</h3><p>reduce2最大的问题就是线程的浪费。可以看到我们启动了256个线程，但是在第1轮迭代时只有128个线程在干活，第2轮迭代只有64个线程在干活，每次干活的线程都会减少一半。第一轮迭代示意图如下，只有前128个线程在load数据。后128个线程啥也不干，光看着。</p><p>每一轮迭代都有一半的线程不工作，要把所有的线程利用起来。</p><p>想来想去，那这样吧，让它好歹做一次加法。除了去global memory中取数外，再做一次加法。当然为了实现这个，block数就得改一改了。Block数量减少，Num_per_block增加一倍。也就是说原来一个block只需要管256个数就行，现在得管512个数了。</p><p>每个block还是256个线程，不同的地方在于每个block里边会处理512个数据，这样一来grid中block的数量也减少了一半。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce3</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock*<span class="hljs-number">2</span>];<br><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * (blockDim.x*<span class="hljs-number">2</span>);<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        sdata[tid] = d_in[i] + d_in[i + blockDim.x];<br>        __syncthreads();<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = blockDim.x/<span class="hljs-number">2</span>;s&gt;<span class="hljs-number">0</span>;s/=<span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-keyword">if</span>(tid&lt;s)&#123;<br>                        sdata[tid] += sdata[tid + s];<br>                &#125;<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid==<span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br><br>&#125;<br><br>reduce3&lt;&lt;&lt;blocksPerGrid/<span class="hljs-number">2</span>,threadsPerBlock&gt;&gt;&gt;(d_a,d_partial_c);<br></code></pre></td></tr></table></figure><h3 id="优化4：展开最后一维减少同步"><a href="#优化4：展开最后一维减少同步" class="headerlink" title="优化4：展开最后一维减少同步"></a>优化4：展开最后一维减少同步</h3><p>线程每一次迭代都减半。由于一个warp中的32个线程其实是在一个SIMD单元上，这32个线程每次都是执行同一条指令，这天然地保持了同步状态。当线程束&gt;32时需要同步，反之线程数&lt;32时，就不需要同步了。我们需要在这个时候将syncthreads操作去掉，减少同步所造成的时间浪费。</p><p>所以我们将最后一维进行展开以减少同步。</p><p>需要注意的是<strong>这个地方的cache变量需要使用volatile来进行声明</strong>，它告诉编译器每次赋值时必须将cache[tid]的值返回到全局内存中，而不是简单的读写缓存或寄存器。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//__global__是kernel函数，可从cpu调用,__device__是只能从一个gpu函数调用，不能从cpu调用</span><br><span class="hljs-comment">//volatile 指出变量是随时可能发生变化的,与volatile变量有关的运算,不要进行编译优化,以免出错</span><br><span class="hljs-function">__device__ <span class="hljs-type">void</span> <span class="hljs-title">warpReduce</span><span class="hljs-params">(<span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> *cache,<span class="hljs-type">int</span> tid)</span></span>&#123;<br>        cache[tid] += cache[tid+<span class="hljs-number">32</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">16</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">8</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">4</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">2</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">1</span>];<br>&#125;<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce4</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock*<span class="hljs-number">2</span>];<br><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * (blockDim.x*<span class="hljs-number">2</span>);<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        sdata[tid] = d_in[i] + d_in[i + blockDim.x];<br>        __syncthreads();<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = blockDim.x/<span class="hljs-number">2</span>;s&gt;<span class="hljs-number">32</span>;s/=<span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-keyword">if</span>(tid&lt;s)&#123;<br>                        sdata[tid] += sdata[tid + s];<br>                &#125;<br>                __syncthreads();<br><br>        &#125;<br>        <span class="hljs-comment">//此时s = 32,因为tid&lt;s,只有一个warp里面32个线程了</span><br>        <span class="hljs-keyword">if</span>(tid&lt;<span class="hljs-number">32</span>)&#123;<br>                <span class="hljs-built_in">warpReduce</span>(sdata,tid);<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid==<span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="优化5：完全展开"><a href="#优化5：完全展开" class="headerlink" title="优化5：完全展开"></a>优化5：完全展开</h3><p>对<strong>for循环</strong>进行完全展开，通过这种方式<strong>减少了条件判断的次数</strong>，因而可以实现速度的提升。</p><p>效果一般</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//reduce 完全展开</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce5</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock*<span class="hljs-number">2</span>];<br><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * (blockDim.x*<span class="hljs-number">2</span>);<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        sdata[tid] = d_in[i] + d_in[i + blockDim.x];<br>        __syncthreads();<br><br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">1024</span> &amp;&amp; tid &lt; <span class="hljs-number">512</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">512</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">512</span> &amp;&amp; tid &lt; <span class="hljs-number">256</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">256</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">256</span> &amp;&amp; tid &lt; <span class="hljs-number">128</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">128</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;=<span class="hljs-number">128</span> &amp;&amp; tid &lt; <span class="hljs-number">64</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">64</span>];<br>                __syncthreads();<br>        &#125;<br><br>        <span class="hljs-keyword">if</span>(tid &lt; <span class="hljs-number">32</span>)&#123;<br>                <span class="hljs-built_in">warpReduce</span>(sdata,tid);<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid == <span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="优化6：调整Block大小"><a href="#优化6：调整Block大小" class="headerlink" title="优化6：调整Block大小"></a>优化6：调整Block大小</h3><h3 id="优化7：shuffle指令"><a href="#优化7：shuffle指令" class="headerlink" title="优化7：shuffle指令"></a>优化7：shuffle指令</h3>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>天气晴，明天有雨</title>
    <link href="/2024/06/28/%E9%9A%8F%E7%AC%941/"/>
    <url>/2024/06/28/%E9%9A%8F%E7%AC%941/</url>
    
    <content type="html"><![CDATA[<h4 id="搭建了我的博客"><a href="#搭建了我的博客" class="headerlink" title="搭建了我的博客"></a>搭建了我的博客</h4><p>github 文章永生</p><p>明天加油吧！！！</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>日记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>流体力学</title>
    <link href="/2024/06/28/%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/"/>
    <url>/2024/06/28/%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/</url>
    
    <content type="html"><![CDATA[<p>学习记录</p><p>1.流体研究的前提：连续介质假设<br>2.流体力学的物理量：速度，密度，压强，温度等</p><h3 id="描述流体运动的方法："><a href="#描述流体运动的方法：" class="headerlink" title="描述流体运动的方法："></a>描述流体运动的方法：</h3><p>①拉格朗日法：以一坨流体的某个质点为例，研究这个质点的随时间的变化，即盯着质点看。<br>②欧拉法：在空间取一个范围，即控制体，控制体（固定不动），如控制体中取某位置，研究该位置所在流体的性质，也就是盯着空间看。<br>●总结：拉格朗日法研究的是一坨流体（积分）或者说某个质点（微分）；欧拉法研究的是控制体（积分）或空间点（微分）</p><p><img src="/../images/1713422480785.png" alt="1713422480785"></p><h3 id="流体力学的任务（要解决什么问题）"><a href="#流体力学的任务（要解决什么问题）" class="headerlink" title="流体力学的任务（要解决什么问题）"></a>流体力学的任务（要解决什么问题）</h3><p>例子：血栓的形成，航天器内部气体的流动</p><p>研究一定条件下，任意时刻（t），任意位置（x,y,z）各种物理量（p，ρ，T，v）的分布</p><p>p(x,y,z,t),ρ（x,y,z,t）…..解这些函数，就涉及流体力学的基本方程。</p><h3 id="流体力学的基本方程（控制方程）"><a href="#流体力学的基本方程（控制方程）" class="headerlink" title="流体力学的基本方程（控制方程）"></a>流体力学的基本方程（控制方程）</h3><p>是一个方程组。</p><p>质量守恒</p><p>动量守恒（动量有三个方向，可以列三个方程）</p><p>能量守恒</p><p>要解6个值 P,ρ，T，t，v（u,v,w）速度有三个方向，一共是6个值</p><p>一共是5个方程，所以还要加一个流体力学本身具有的性质所列出的方程。</p><p><img src="/../images/1713423733375.png" alt="1713423733375"></p><h3 id="质量守恒方程（连续方程）"><a href="#质量守恒方程（连续方程）" class="headerlink" title="质量守恒方程（连续方程）"></a>质量守恒方程（连续方程）</h3><h4 id="积分形式的质量守恒"><a href="#积分形式的质量守恒" class="headerlink" title="积分形式的质量守恒"></a>积分形式的质量守恒</h4><p><img src="/../images/1713516753303.png" alt="1713516753303"></p><p><img src="/../images/1713516816649.png" alt="1713516816649"></p><h4 id="微分形式的质量守恒方程"><a href="#微分形式的质量守恒方程" class="headerlink" title="微分形式的质量守恒方程"></a>微分形式的质量守恒方程</h4><p><img src="/../images/1713516848847.png" alt="1713516848847"></p><p><img src="/../images/1713517551714.png" alt="1713517551714"></p><h4 id="散度和梯度"><a href="#散度和梯度" class="headerlink" title="散度和梯度"></a>散度和梯度</h4><p><img src="/../images/1713517596596.png" alt="1713517596596"></p><p><img src="/../images/1713517639356.png" alt="1713517639356"></p><h4 id="两种特殊情况"><a href="#两种特殊情况" class="headerlink" title="两种特殊情况"></a>两种特殊情况</h4><p>定常流动：流动是稳定的，不随时间而改变</p><p><img src="/../images/1713518306247.png" alt="1713518306247"></p><p>不可压流动：ρ为常数</p><h5 id=""><a href="#" class="headerlink" title=""></a><img src="/../images/1713518419990.png" alt="1713518419990"></h5><h4 id="连续方程微分形式的第二种推导方法"><a href="#连续方程微分形式的第二种推导方法" class="headerlink" title="连续方程微分形式的第二种推导方法"></a>连续方程微分形式的第二种推导方法</h4><p>略</p><p>散度的物理意义：</p><p><img src="/../images/1713520658383.png" alt="1713520658383"></p><p>速度散度：单位体积单位时间的体积变化</p><p><img src="/../images/1713520754996.png" alt="1713520754996"></p><h4 id="定常准一维流动的连续方程"><a href="#定常准一维流动的连续方程" class="headerlink" title="定常准一维流动的连续方程"></a>定常准一维流动的连续方程</h4><p>ρuA&#x3D;常数</p><p><img src="/../images/1713522073052.png" alt="1713522073052"></p><h3 id="动量守恒方程"><a href="#动量守恒方程" class="headerlink" title="动量守恒方程"></a>动量守恒方程</h3><h3 id="能量守恒方程"><a href="#能量守恒方程" class="headerlink" title="能量守恒方程"></a>能量守恒方程</h3>]]></content>
    
    
    <categories>
      
      <category>cfd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>cfd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo_github遇到的问题</title>
    <link href="/2024/06/28/hexo_github%E9%85%8D%E7%BD%AE/"/>
    <url>/2024/06/28/hexo_github%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h3 id="冒号后面要加空格"><a href="#冒号后面要加空格" class="headerlink" title="冒号后面要加空格"></a>冒号后面要加空格</h3><h3 id="repo写以下格式"><a href="#repo写以下格式" class="headerlink" title="repo写以下格式"></a>repo写以下格式</h3><p><img src="/../images/1719557282413.png"></p><h3 id="master分支设置"><a href="#master分支设置" class="headerlink" title="master分支设置"></a>master分支设置</h3><p><img src="/../images/1719557364439.png"></p><p><img src="/../images/1719557376929.png"></p>]]></content>
    
    
    <categories>
      
      <category>喜欢捣鼓</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>加载图片，研究一下</title>
    <link href="/2024/06/28/%E5%8A%A0%E8%BD%BD%E5%9B%BE%E7%89%87/"/>
    <url>/2024/06/28/%E5%8A%A0%E8%BD%BD%E5%9B%BE%E7%89%87/</url>
    
    <content type="html"><![CDATA[<p><img src="/../images/a.jpeg" alt="车"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/06/25/hello-world/"/>
    <url>/2024/06/25/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
