<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>c转hipc</title>
    <link href="/2024/07/09/cTohipc/"/>
    <url>/2024/07/09/cTohipc/</url>
    
    <content type="html"><![CDATA[<h1 id="c转hipc"><a href="#c转hipc" class="headerlink" title="c转hipc"></a>c转hipc</h1><p>cuda 类比 hip</p><p>如果您将 <code>add</code> 和 <code>myKernel</code> 函数分别写在不同的文件中，并希望在主函数中调用 <code>myKernel</code> 函数，需要进行以下步骤：</p><ol><li><p><strong>定义 add 函数的头文件</strong>：创建一个头文件（例如 <code>cuda_functions.h</code>），在其中声明 <code>add</code> 函数为 <code>__device__</code> 函数。myKernel函数为<code>__global__</code>函数</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cpp<br><span class="hljs-comment">// cuda_functions.h</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> CUDA_FUNCTIONS_H</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CUDA_FUNCTIONS_H</span><br><br><span class="hljs-function">__device__ <span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span></span>;<br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">myKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *array, <span class="hljs-type">int</span> N)</span></span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span> <span class="hljs-comment">// CUDA_FUNCTIONS_H</span></span><br></code></pre></td></tr></table></figure></li><li><p><strong>实现 add 函数的源文件</strong>：创建一个源文件（例如 <code>cuda_functions.cu</code>），在其中定义 <code>add</code> 函数的实现。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cpp<br><span class="hljs-comment">// cuda_functions.cu</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_functions.h&quot;</span></span><br><br><span class="hljs-function">__device__ <span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> a + b;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>定义 myKernel 函数的源文件</strong>：创建另一个源文件（例如 <code>my_kernel.cu</code>），在其中定义 <code>myKernel</code> 函数。</p><figure class="highlight stan"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stan">cpp<br><span class="hljs-comment">// my_kernel.cu</span><br><br><span class="hljs-meta">#include &quot;<span class="hljs-string">cuda_functions.h</span>&quot;</span><br><br>__global__ <span class="hljs-type">void</span> myKernel(<span class="hljs-type">int</span> *<span class="hljs-type">array</span>, <span class="hljs-type">int</span> N) &#123;<br>    <span class="hljs-type">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-keyword">if</span> (idx &lt; N) &#123;<br>        <span class="hljs-comment">// 调用子函数</span><br>        <span class="hljs-type">array</span>[idx] = add(<span class="hljs-type">array</span>[idx], <span class="hljs-number">5</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>主函数中的调用</strong>：在主函数中包含头文件 <code>cuda_functions.h</code>，并调用 <code>myKernel</code> 函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cpp<br><span class="hljs-comment">// main.cpp</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_functions.h&quot;</span></span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">10</span>;<br>    <span class="hljs-type">int</span> array[N];<br><br>    <span class="hljs-type">int</span> *d_array;<br>    <span class="hljs-built_in">cudaMalloc</span>((<span class="hljs-type">void</span> **)&amp;d_array, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_array, array, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), cudaMemcpyHostToDevice);<br><br>    <span class="hljs-type">int</span> blockSize = <span class="hljs-number">256</span>;<br>    <span class="hljs-type">int</span> numBlocks = (N + blockSize - <span class="hljs-number">1</span>) / blockSize;<br>    myKernel&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(d_array, N);<br><br>    <span class="hljs-built_in">cudaMemcpy</span>(array, d_array, N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>), cudaMemcpyDeviceToHost);<br><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Modified array:&quot;</span> &lt;&lt; std::endl;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; ++i) &#123;<br>        std::cout &lt;&lt; array[i] &lt;&lt; <span class="hljs-string">&quot; &quot;</span>;<br>    &#125;<br>    std::cout &lt;&lt; std::endl;<br><br>    <span class="hljs-built_in">cudaFree</span>(d_array);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>编译</strong>：在编译时，需要将所有 <code>.cu</code> 文件都传递给CUDA编译器 <code>nvcc</code>，并链接相应的CUDA库。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">nvcc -o my_program <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.cpp</span> cuda_functions<span class="hljs-selector-class">.cu</span> my_kernel.cu<br></code></pre></td></tr></table></figure></li></ol><p>通过这样的方式，您可以将 CUDA 核函数和其它设备函数分别放置在不同的文件中，并在主函数中正确地调用和使用它们。</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gemm优化（代码实现）</title>
    <link href="/2024/07/07/gemm%E4%BC%98%E5%8C%96_%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <url>/2024/07/07/gemm%E4%BC%98%E5%8C%96_%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="1-参考资料"><a href="#1-参考资料" class="headerlink" title="1 参考资料"></a>1 参考资料</h2><p><a href="https://zhuanlan.zhihu.com/p/442930482">深入浅出GPU优化系列：GEMM优化（二） - 知乎 (zhihu.com)</a></p><p>代码：</p><p><a href="https://github.com/Liu-xiandong/How_to_optimize_in_GPU/tree/master/sgemm">How_to_optimize_in_GPU&#x2F;sgemm at master · Liu-xiandong&#x2F;How_to_optimize_in_GPU (github.com)</a></p><h2 id="2-1-参数说明"><a href="#2-1-参数说明" class="headerlink" title="2.1 参数说明"></a>2.1 参数说明</h2><p>模板参数是GEMM性能调优的关键。不同参数对GEMM性能的影响很大。以下是主要模板参数的说明：</p><ul><li><code>BLOCK_SIZE_M</code>: 每个块计算的C矩阵的高度。</li><li><code>BLOCK_SIZE_K</code>: 每个块从A矩阵加载到共享内存的宽度。</li><li><code>BLOCK_SIZE_N</code>: 每个块计算的C矩阵的宽度。</li><li><code>THREAD_SIZE_Y</code>: 每个线程计算的C矩阵的高度。</li><li><code>THREAD_SIZE_X</code>: 每个线程计算的C矩阵的宽度。</li><li><code>ENABLE_DOUBLE_BUFFER</code>: 是否启用双缓冲（数据预取）。</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">template</span> &lt;<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> BLOCK_SIZE_M,<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> BLOCK_SIZE_K,<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> BLOCK_SIZE_N,<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_SIZE_Y,<br>    <span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_SIZE_X,<br>    <span class="hljs-type">const</span> <span class="hljs-type">bool</span> ENABLE_DOUBLE_BUFFER<br>    &gt;<br></code></pre></td></tr></table></figure><p>接下来是线程的相关参数。256个block按照二维形态排布，每个block中有256个线程，同样以二维形态排布。以下是主要线程参数的说明：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Block index</span><br><span class="hljs-type">int</span> bx = blockIdx.x;<br><span class="hljs-type">int</span> by = blockIdx.y;<br><br><span class="hljs-comment">// Thread index</span><br><span class="hljs-type">int</span> tx = threadIdx.x;<br><span class="hljs-type">int</span> ty = threadIdx.y;<br><br><span class="hljs-comment">// the threads number in Block of X,Y</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_X_PER_BLOCK = BLOCK_SIZE_N / THREAD_SIZE_X;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_Y_PER_BLOCK = BLOCK_SIZE_M / THREAD_SIZE_Y;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> THREAD_NUM_PER_BLOCK = THREAD_X_PER_BLOCK * THREAD_Y_PER_BLOCK;<br><br><span class="hljs-comment">// thread id in cur Block</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> tid = ty * THREAD_X_PER_BLOCK + tx;<br></code></pre></td></tr></table></figure><p>在global memory到shared memory的数据搬运中，还需要经过寄存器。以下是一些共享内存和寄存器的分配说明：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// shared memory</span><br>__shared__ <span class="hljs-type">float</span> As[<span class="hljs-number">2</span>][BLOCK_SIZE_K][BLOCK_SIZE_M];<br>__shared__ <span class="hljs-type">float</span> Bs[<span class="hljs-number">2</span>][BLOCK_SIZE_K][BLOCK_SIZE_N];<br><span class="hljs-comment">// registers for C</span><br><span class="hljs-type">float</span> accum[THREAD_SIZE_Y][THREAD_SIZE_X] = &#123;<span class="hljs-number">0</span>&#125;;<br><span class="hljs-comment">// registers for A and B</span><br><span class="hljs-comment">//计算时用到的寄存器，存储每一轮小迭代存储的数据</span><br><span class="hljs-type">float</span> frag_a[<span class="hljs-number">2</span>][THREAD_SIZE_Y];<br><span class="hljs-type">float</span> frag_b[<span class="hljs-number">2</span>][THREAD_SIZE_X];<br><span class="hljs-comment">// registers load global memory</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> ldg_num_a = BLOCK_SIZE_M * BLOCK_SIZE_K / (THREAD_NUM_PER_BLOCK * <span class="hljs-number">4</span>);<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> ldg_num_b = BLOCK_SIZE_K * BLOCK_SIZE_N / (THREAD_NUM_PER_BLOCK * <span class="hljs-number">4</span>);<br><span class="hljs-comment">//从global mem &gt; share mem 中间需要的寄存器</span><br><span class="hljs-type">float</span> ldg_a_reg[<span class="hljs-number">4</span>*ldg_num_a];<br><span class="hljs-type">float</span> ldg_b_reg[<span class="hljs-number">4</span>*ldg_num_b];<br></code></pre></td></tr></table></figure><p>为了优化内存访问，我们定义了一些宏：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> OFFSET(row, col, ld) ((row) * (ld) + (col))</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> FETCH_FLOAT4(pointer) (reinterpret_cast<span class="hljs-string">&lt;float4*&gt;</span>(&amp;(pointer))[0])</span><br></code></pre></td></tr></table></figure><p><strong>define OFFSET(row, col, ld) ((row) * (ld) + (col)):</strong></p><p>该宏用于计算二维数组在一维内存中的偏移量。</p><p><strong>#define FETCH_FLOAT4(pointer) (reinterpret_cast&lt;float4*&gt;(&amp;(pointer))[0])</strong></p><p>该宏用于一次性读取4个连续的<code>float</code>数据。</p><p><strong>解释</strong></p><ul><li>&amp;(pointer)：获取pointer的地址。</li><li><code>reinterpret_cast&lt;float4*&gt;(&amp;(pointer))</code>：将<code>pointer</code>的地址强制转换为指向<code>float4</code>类型的指针。<code>float4</code>是CUDA中的一种数据类型，表示包含4个<code>float</code>的向量。</li><li><code>[0]</code>：解引用该指针，获取<code>float4</code>类型的值。</li></ul><p>这实际上是从内存中读取4个连续的<code>float</code>值，并将它们作为一个<code>float4</code>返回。</p><p><strong>举例</strong></p><p>假设我们有一个连续的<code>float</code>数组：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">cpp<br>复制代码<br><span class="hljs-built_in">float</span> A[<span class="hljs-number">8</span>] = &#123;<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>&#125;;<br></code></pre></td></tr></table></figure><p>如果我们希望一次性读取前4个值，可以使用该宏：</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">cpp<br>复制代码<br><span class="hljs-built_in">float</span>4 f4 = FETCH_FLOAT4(A[<span class="hljs-number">0</span>]);<br><span class="hljs-comment">// 结果是 f4.x = 0.0, f4.y = 1.0, f4.z = 2.0, f4.w = 3.0</span><br></code></pre></td></tr></table></figure><h2 id="2-2-大迭代前预取数据"><a href="#2-2-大迭代前预取数据" class="headerlink" title="2.2 大迭代前预取数据"></a>2.2 大迭代前预取数据</h2><p>迭代前预取数据分为<strong>两个部分</strong>，<strong>第一个部分</strong>是将第一个大迭代的数据从global 预取到shared memroy中。<strong>第二个部分</strong>是将shared memory上的数据预取到寄存器中。</p><p>第一个部分**是将第一个大迭代的数据从global 预取到shared memroy中。</p><p>先来看看<strong>第一个部分</strong>。这里面分别是将第一个大迭代中需要的A、B数据预取到shared memroy中。对于A矩阵而言，这个for循环代表着block中的线程需要搬运多少次才能将globa中的数据放到shared memory中。由于A需要先进行一次转置，所以先将数据先放置在寄存器中。数据按行取，然后按列存。对于B矩阵而言，数据不用转置，直接按行取，按行存。当然，这个过程中间也要经过寄存器，但是没有写出来的必要了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// load A from global memory to shared memory</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_M; i += A_TILE_ROW_STRIDE) &#123;<br>    <span class="hljs-type">int</span> ldg_index = i / A_TILE_ROW_STRIDE * <span class="hljs-number">4</span>;<br>    <span class="hljs-comment">//先将一个大迭代的数据读取到global mem &gt; shread mem 中间的寄存器中</span><br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(ldg_a_reg[ldg_index]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(A[<span class="hljs-built_in">OFFSET</span>(<br>        BLOCK_SIZE_M * by + A_TILE_ROW_START + i, <span class="hljs-comment">// row</span><br>        A_TILE_COL, <span class="hljs-comment">// col</span><br>        K )]);<br>    <span class="hljs-comment">//再将寄存器的数据读取到shared mem 中，这样就完成了第一次大迭代的数据预取</span><br>    As[<span class="hljs-number">0</span>][A_TILE_COL][A_TILE_ROW_START + i]=ldg_a_reg[ldg_index];<br>    As[<span class="hljs-number">0</span>][A_TILE_COL+<span class="hljs-number">1</span>][A_TILE_ROW_START + i]=ldg_a_reg[ldg_index+<span class="hljs-number">1</span>];<br>    As[<span class="hljs-number">0</span>][A_TILE_COL+<span class="hljs-number">2</span>][A_TILE_ROW_START + i]=ldg_a_reg[ldg_index+<span class="hljs-number">2</span>];<br>    As[<span class="hljs-number">0</span>][A_TILE_COL+<span class="hljs-number">3</span>][A_TILE_ROW_START + i]=ldg_a_reg[ldg_index+<span class="hljs-number">3</span>];<br>&#125;<br><br><span class="hljs-comment">// load B from global memory to shared memory</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_K; i += B_TILE_ROW_STRIDE) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[<span class="hljs-number">0</span>][B_TILE_ROW_START + i][B_TILE_COL]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(B[<span class="hljs-built_in">OFFSET</span>(<br>        B_TILE_ROW_START + i, <span class="hljs-comment">// row</span><br>        B_TILE_COL + BLOCK_SIZE_N * bx, <span class="hljs-comment">// col</span><br>        N )]);<br>&#125;<br>__syncthreads();<br></code></pre></td></tr></table></figure><p>第二个部分**是将shared memory上的数据预取到寄存器中</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// load A from shared memory to register</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; thread_y += <span class="hljs-number">4</span>) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_a[<span class="hljs-number">0</span>][thread_y]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(As[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][THREAD_SIZE_Y * ty + thread_y]);<br>&#125;<br><br><span class="hljs-comment">// load B from shared memory to register</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; thread_x += <span class="hljs-number">4</span>) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_b[<span class="hljs-number">0</span>][thread_x]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][THREAD_SIZE_X * tx + thread_x]);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-3-大迭代逻辑"><a href="#2-3-大迭代逻辑" class="headerlink" title="2.3 大迭代逻辑"></a>2.3 大迭代逻辑</h2><p>每个大迭代加载新的数据块，并执行一系列的小迭代。我们先设置一些参数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> write_stage_idx = <span class="hljs-number">1</span>;<br><span class="hljs-type">int</span> tile_idx = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">do</span> &#123;<br>    tile_idx += BLOCK_SIZE_K;<br>    <span class="hljs-type">int</span> load_stage_idx = write_stage_idx ^ <span class="hljs-number">1</span>;<br>    <span class="hljs-comment">// compute</span><br>    <span class="hljs-keyword">if</span> (tile_idx &lt; K) &#123;<br>        write_stage_idx ^= <span class="hljs-number">1</span>;<br>    &#125;<br>&#125; <span class="hljs-keyword">while</span> (tile_idx &lt; K);<br></code></pre></td></tr></table></figure><h2 id="2-4-大迭代详细解析"><a href="#2-4-大迭代详细解析" class="headerlink" title="2.4 大迭代详细解析"></a>2.4 大迭代详细解析</h2><h3 id="1-在大迭代中，我们将global-memory的数据块搬运到中间寄存器："><a href="#1-在大迭代中，我们将global-memory的数据块搬运到中间寄存器：" class="headerlink" title="1.在大迭代中，我们将global memory的数据块搬运到中间寄存器："></a>1.在大迭代中，我们将global memory的数据块搬运到中间寄存器：</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c++">tile_idx += BLOCK_SIZE_K;<br><span class="hljs-keyword">if</span> (tile_idx &lt; K) &#123;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_M; i += A_TILE_ROW_STRIDE) &#123;<br>        <span class="hljs-type">int</span> ldg_index = i / A_TILE_ROW_STRIDE * <span class="hljs-number">4</span>;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(ldg_a_reg[ldg_index]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(A[<span class="hljs-built_in">OFFSET</span>(<br>            BLOCK_SIZE_M * by + A_TILE_ROW_START + i, <span class="hljs-comment">// row</span><br>            A_TILE_COL + tile_idx, <span class="hljs-comment">// col</span><br>            K )]);<br>    &#125;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_K; i += B_TILE_ROW_STRIDE) &#123;<br>        <span class="hljs-type">int</span> ldg_index = i / A_TILE_ROW_STRIDE * <span class="hljs-number">4</span>;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(ldg_b_reg[ldg_index]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(B[<span class="hljs-built_in">OFFSET</span>(<br>            tile_idx + B_TILE_ROW_START + i, <span class="hljs-comment">// row</span><br>            B_TILE_COL + BLOCK_SIZE_N * bx, <span class="hljs-comment">// col</span><br>            N )]);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-进入小迭代的计算逻辑：将shared-mem-的数据存储到寄存器中"><a href="#2-进入小迭代的计算逻辑：将shared-mem-的数据存储到寄存器中" class="headerlink" title="2.进入小迭代的计算逻辑：将shared mem 的数据存储到寄存器中"></a>2.进入小迭代的计算逻辑：将shared mem 的数据存储到寄存器中</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> load_stage_idx = write_stage_idx ^ <span class="hljs-number">1</span>;<br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; BLOCK_SIZE_K - <span class="hljs-number">1</span>; ++j) &#123;<br>    <span class="hljs-comment">// load next tile from shared mem to register </span><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; thread_y += <span class="hljs-number">4</span>) &#123;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_a[(j + <span class="hljs-number">1</span>) % <span class="hljs-number">2</span>][thread_y]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(As[load_stage_idx][j + <span class="hljs-number">1</span>][THREAD_SIZE_Y * ty + thread_y]);<br>    &#125;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; thread_x += <span class="hljs-number">4</span>) &#123;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_b[(j + <span class="hljs-number">1</span>) % <span class="hljs-number">2</span>][thread_x]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[load_stage_idx][j + <span class="hljs-number">1</span>][THREAD_SIZE_X * tx + thread_x]);<br>    &#125;<br>    <span class="hljs-comment">// compute C THREAD_SIZE_X x THREAD_SIZE_Y</span><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; ++thread_y) &#123;<br>        <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; ++thread_x) &#123;<br>            accum[thread_y][thread_x] += frag_a[j % <span class="hljs-number">2</span>][thread_y] * frag_b[j % <span class="hljs-number">2</span>][thread_x];<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-将数据从寄存器搬运到shared-memory："><a href="#3-将数据从寄存器搬运到shared-memory：" class="headerlink" title="3.将数据从寄存器搬运到shared memory："></a>3.将数据从寄存器搬运到shared memory：</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">if</span> (tile_idx &lt; K) &#123;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_M; i += A_TILE_ROW_STRIDE) &#123;<br>        <span class="hljs-type">int</span> ldg_index = i / A_TILE_ROW_STRIDE * <span class="hljs-number">4</span>;<br>        As[write_stage_idx][A_TILE_COL][A_TILE_ROW_START + i] = ldg_a_reg[ldg_index];<br>        As[write_stage_idx][A_TILE_COL + <span class="hljs-number">1</span>][A_TILE_ROW_START + i] = ldg_a_reg[ldg_index + <span class="hljs-number">1</span>];<br>        As[write_stage_idx][A_TILE_COL + <span class="hljs-number">2</span>][A_TILE_ROW_START + i] = ldg_a_reg[ldg_index + <span class="hljs-number">2</span>];<br>        As[write_stage_idx][A_TILE_COL + <span class="hljs-number">3</span>][A_TILE_ROW_START + i] = ldg_a_reg[ldg_index + <span class="hljs-number">3</span>];<br>    &#125;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; BLOCK_SIZE_K; i += B_TILE_ROW_STRIDE) &#123;<br>        <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[write_stage_idx][B_TILE_ROW_START + i][B_TILE_COL]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(ldg_b_reg[ldg_index]);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-最后，将shared-memory的数据块加载到寄存器，完成寄存器的预取，并将最后一个小迭代完成"><a href="#4-最后，将shared-memory的数据块加载到寄存器，完成寄存器的预取，并将最后一个小迭代完成" class="headerlink" title="4.最后，将shared memory的数据块加载到寄存器，完成寄存器的预取，并将最后一个小迭代完成"></a>4.最后，将shared memory的数据块加载到寄存器，完成寄存器的预取，并将最后一个小迭代完成</h3><p>“最后一个小迭代？”是为了处理前七次迭代没有处理过的最后的一部分矩阵相乘。“最后完成寄存器的预取”这一部分是为下一次大迭代的第一次小迭代进行预取，不是为了本次大迭代的最后一次小迭代预取。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// load A from shared memory to register</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; thread_y += <span class="hljs-number">4</span>) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_a[<span class="hljs-number">0</span>][thread_y]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(As[write_stage_idx][<span class="hljs-number">0</span>][THREAD_SIZE_Y * ty + thread_y]);<br>&#125;<br><span class="hljs-comment">// load B from shared memory to register</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; thread_x += <span class="hljs-number">4</span>) &#123;<br>    <span class="hljs-built_in">FETCH_FLOAT4</span>(frag_b[<span class="hljs-number">0</span>][thread_x]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(Bs[write_stage_idx][<span class="hljs-number">0</span>][THREAD_SIZE_X * tx + thread_x]);<br>&#125;<br><span class="hljs-comment">//compute last tile mma THREAD_SIZE_X x THREAD_SIZE_Y</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; ++thread_y) &#123;<br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; ++thread_x) &#123;<br>        accum[thread_y][thread_x] += frag_a[<span class="hljs-number">1</span>][thread_y] * frag_b[<span class="hljs-number">1</span>][thread_x];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="5-计算结果写回"><a href="#5-计算结果写回" class="headerlink" title="5.计算结果写回"></a>5.计算结果写回</h3><p>此时，最后的计算结果已经被存储在<code>accum</code>寄存器中，需要将其写回到global memory中。这个代码比较简单，就没啥好说的了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// store back to C</span><br>    <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_y = <span class="hljs-number">0</span>; thread_y &lt; THREAD_SIZE_Y; ++thread_y) &#123;<br>        <span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> thread_x = <span class="hljs-number">0</span>; thread_x &lt; THREAD_SIZE_X; thread_x+=<span class="hljs-number">4</span>) &#123;<br>            <span class="hljs-built_in">FETCH_FLOAT4</span>(C[<span class="hljs-built_in">OFFSET</span>(<br>                BLOCK_SIZE_M * by + ty * THREAD_SIZE_Y + thread_y,<br>                BLOCK_SIZE_N * bx + tx * THREAD_SIZE_X + thread_x,<br>                N)]) = <span class="hljs-built_in">FETCH_FLOAT4</span>(accum[thread_y][thread_x]);<br>        &#125;<br>    &#125;<br></code></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过采用数据预取和双缓冲技术，我们可以大大提高GEMM的计算效率。这种方法确保了在大部分计算过程中，计算单元都在忙碌地进行计算，而不是在等待数据传输。这种优化方法在大型矩阵乘法中尤其有效。</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>纪念</title>
    <link href="/2024/07/03/%E7%BA%AA%E5%BF%B5/"/>
    <url>/2024/07/03/%E7%BA%AA%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<p>今天没开组会，结束了一轮的训练</p><p>找到了很好看的美剧，无耻之徒</p><p>明天是我的生日，有谁会记得呢？</p><p>23岁结束，24岁，加油</p><p>明天下雨，早上好好睡觉吧，休息一下吧，晚上吃点好的。</p><p><img src="/../images/1720012074393.png" alt="1720012074393"></p><p>尺度有点大</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>日记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gemm优化</title>
    <link href="/2024/07/02/gemm%E4%BC%98%E5%8C%96/"/>
    <url>/2024/07/02/gemm%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="Gemm-优化"><a href="#Gemm-优化" class="headerlink" title="Gemm 优化"></a>Gemm 优化</h1><p><strong>参考资料</strong></p><p><a href="https://zhuanlan.zhihu.com/p/435908830">深入浅出GPU优化系列：GEMM优化（一） - 知乎 (zhihu.com)</a></p><h2 id="整体思路"><a href="#整体思路" class="headerlink" title="整体思路"></a>整体思路</h2><h3 id="分块"><a href="#分块" class="headerlink" title="分块"></a>分块</h3><p><strong>分块是针对整个问题，先成条，即每个block，再分成block的每一次大迭代，再分成大迭代中的每次小迭代。</strong></p><p><strong>先分成条（block），再分成更小的条（大迭代），再分。</strong></p><p>取bm&#x3D;128,bn&#x3D;128,bk&#x3D;8,rm&#x3D;8,rn&#x3D;8</p><p>A，B，C，其维度都是2048×2048</p><p>要求解C&#x3D;A×B。那么我们需要开启（2048&#x2F;128）×（2048&#x2F;128）&#x3D;<strong>256个block</strong>，</p><p>每个block里面有（128&#x2F;8）×（128&#x2F;8）&#x3D;<strong>256个线程</strong>，</p><p>每个线程需要负责计算C矩阵中8×8&#x3D;64个元素的结果，每个block负责256×64&#x3D;16384个元素的结果。</p><p><img src="/../images/1719926905491.png" alt="1719926905491"></p><p>一个block算的是，128 × 2048 ，2048 × 128 ，大长条（block）。</p><p><img src="/../images/1719927479717.png" alt="1719927479717"></p><p><img src="/../images/1719927489368.png" alt="1719927489368"></p><p>block中有K次大迭代，K&#x3D; k&#x2F;bk&#x3D;2048&#x2F;8 &#x3D; 256，一次大迭代算的是128 × 8     8 × 128</p><p>小条（大迭代）</p><p><img src="/../images/1719927530708.png" alt="1719927530708"></p><p><img src="/../images/1719927534500.png" alt="1719927534500"></p><p>bk &#x3D; 8 每个线程有8次小迭代，一次小迭代算的是 8 × 1   1 × 8</p><p>更小的条（小迭代），把上面的图放大</p><p><img src="/../images/1719927620368.png" alt="1719927620368"></p><h3 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h3><p><strong>迭代是针对一个block进行的，每一个block都要进行256次大迭代，每个大迭代里面又有8个小迭代</strong></p><p><strong>即：写代码的逻辑</strong></p><p>明确了上面的参数之后，我们来仔细地观察其中<strong>一个block</strong>的计算逻辑。对于这个block而言，它需要进行2048&#x2F;8&#x3D;256次迭代，我们先把这个迭代称为<strong>大迭代</strong>，每一次大迭代都需要把A里面128×8&#x3D;1024个元素和B里面8×128&#x3D;1024个元素先放到shared memory中。然后这个block中的256个线程把结果计算出来。计算完之后，再进入下一次大迭代。不断重复该过程，直至这个block负责的16384个元素的结果被求解出。大迭代示意图如下：</p><p><img src="/../images/1719926415038.png" alt="1719926415038"></p><p>随后再具体看看每一个大迭代中，block中的线程的计算逻辑。在进行一个大迭代时，shared memory中有128×8&#x3D;1024个A矩阵元素和8×128&#x3D;1024个B矩阵元素。随后，每个线程需要进行8次迭代，我们把这个迭代成为<strong>小迭代</strong>。bk&#x3D;8，所以有8次小迭代。每一次小迭代中，每个线程需要从shared memory中拿到A矩阵的一小列和B矩阵的一小行，即8个A的元素和8个B的元素。线程将这8+8&#x3D;16个元素放置在寄存器中。每个线程需要负责8×8&#x3D;64个元素的计算，一共会产生64条FFMA指令。小迭代示意图如下：</p><p><img src="/../images/1719926427313.png" alt="1719926427313"></p><p>总的来说，<strong>对于一个block而言，有256个大迭代，每个大迭代中又有8个小迭代</strong></p><p>总之很绕，看了好久，脑子里有个模糊的概念了。然后看代码的实现吧，明天开组会讲点啥呢？</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gemm+im2col</title>
    <link href="/2024/07/01/gemm_im2col/"/>
    <url>/2024/07/01/gemm_im2col/</url>
    
    <content type="html"><![CDATA[<h2 id="gemm-im2col"><a href="#gemm-im2col" class="headerlink" title="gemm+im2col"></a>gemm+im2col</h2><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://blog.csdn.net/taoqick/article/details/129051936">高性能卷积计算：img2col 原理详解-CSDN博客</a></p><p><a href="https://seanwangjs.github.io/2022/04/28/im2col-programming.html">使用 C++ 实现 im2col 操作 - Fenrier Lab (seanwangjs.github.io)</a></p><h3 id="im2col"><a href="#im2col" class="headerlink" title="im2col"></a>im2col</h3><p>img2col 是一种实现卷积操作的加速计算策略。它能将卷积操作转化为 GEMM，从而最大化地缩短卷积计算的时间。</p><h4 id="为什么要将卷积操作转化为-GEMM-呢？"><a href="#为什么要将卷积操作转化为-GEMM-呢？" class="headerlink" title="为什么要将卷积操作转化为 GEMM 呢？"></a><strong>为什么要将卷积操作转化为 GEMM 呢？</strong></h4><p>1.因为线性代数领域已经有非常成熟的计算接口（BLAS，Fortran 语言实现）来高效地实现大型的矩阵乘法，几乎可以做到极限优化。</p><p>2.将卷积过程中用到的所有特征子矩阵整合成一个大型矩阵存放在连续的内存中，虽然增加了存储成本，但是减少了内存访问的次数，从而缩短了计算时间。</p><h4 id="img2col将卷积操作转化为GEMM过程"><a href="#img2col将卷积操作转化为GEMM过程" class="headerlink" title="img2col将卷积操作转化为GEMM过程"></a>img2col将卷积操作转化为GEMM过程</h4><p><img src="/../images/1719824785939.png" alt="1719824785939"></p><h5 id="1-Input-Features-Input-Matrix"><a href="#1-Input-Features-Input-Matrix" class="headerlink" title="1.Input Features &gt; Input Matrix"></a>1.Input Features &gt; Input Matrix</h5><p><img src="/../images/1719824926813.png" alt="1719824926813"></p><p>输入特征图有三个通道，用三个不同的颜色来表示</p><p>因为卷积核的大小为2乘2，当卷积核的滑动步长为1的时候，那么传统的直接卷积计算一共需要进行 4 次卷积核与对应特征子矩阵之间的点积运算。</p><p>现在把每一个子矩阵都排列成一个行向量，就得到了三个通道的特征图对应的三个矩阵（Input Matrix）</p><h5 id="2-Convolution-Kernel-Kernel-Matrix"><a href="#2-Convolution-Kernel-Kernel-Matrix" class="headerlink" title="2.Convolution Kernel &gt; Kernel Matrix"></a>2.Convolution Kernel &gt; Kernel Matrix</h5><p><img src="/../images/1719825159189.png" alt="1719825159189"></p><p>卷积核有两个，每一个也是三通道的，我们研究其中一个卷积核</p><p>将卷积核转换为列向量，然后再把每一个通道对应的 Kernel Matrix 堆叠成一个完整的 Kernel Matrix。</p><h5 id="3-Input-Matrix-Kernel-Matrix-Output-Matrix"><a href="#3-Input-Matrix-Kernel-Matrix-Output-Matrix" class="headerlink" title="3.Input Matrix * Kernel Matrix &#x3D; Output Matrix"></a>3.Input Matrix * Kernel Matrix &#x3D; Output Matrix</h5><p>调用GEMM接口，将两个矩阵进行乘积。然后将输出矩阵通过 col2img 函数就可以得到和卷积运算一样的输出特征图。</p><p><img src="/../images/1719825458677.png" alt="1719825458677"></p><h4 id="c-代码实现im2col"><a href="#c-代码实现im2col" class="headerlink" title="c++代码实现im2col"></a>c++代码实现im2col</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">im2col</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span>* data_im, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> im_c, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> im_w, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> im_h, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> kw, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> kh, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> ph, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> pw, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> sh,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> sw,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">float</span>* data_col, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> col_w, </span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">int</span> col_h)</span> </span>&#123;<br><br>        <span class="hljs-comment">// win_w and win_h are the stop times of the kernel in the image.</span><br>        <span class="hljs-type">int</span> win_w = (im_w + <span class="hljs-number">2</span> * pw - kw + <span class="hljs-number">1</span>) / sw;<br>        <span class="hljs-type">int</span> win_h = (im_h + <span class="hljs-number">2</span> * ph - kh + <span class="hljs-number">1</span>) / sh;<br><br>        <br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i&lt; col_h; i++) &#123;<br><br>            x = i % win_w;<br>            y = i / win_w;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; col_w; j++) &#123;<br>                <span class="hljs-type">int</span> c = j / (kw * kh);<br>                <span class="hljs-type">int</span> kj = j % kw;<br>                <span class="hljs-type">int</span> ki = j / kw;<br><br>                <span class="hljs-type">int</span> row = y * sh + ki;<br>                <span class="hljs-type">int</span> col = x * sw + kj;<br><br>                data_col[i * col_w + j] = <span class="hljs-built_in">get_data</span>(data_im, c, im_w, im_h, row, col, ph, pw);<br>            &#125;<br>        &#125;<br><br>    &#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cublas库 学习</title>
    <link href="/2024/07/01/cublas%E5%BA%93/"/>
    <url>/2024/07/01/cublas%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h2 id="cublas库"><a href="#cublas库" class="headerlink" title="cublas库"></a>cublas库</h2><h3 id="what-is-cublas？"><a href="#what-is-cublas？" class="headerlink" title="what is cublas？"></a>what is cublas？</h3><p>CUDA Basic Linear Algebra Subprograms（BLAS）提供了高效计算线性代数的方法。</p><p>有三级API和cuBLAS 扩展、辅助API：</p><p>最基础操作，例如加、减、最大值、复制、转置<br>矩阵的一般操作，例如特殊类型矩阵的乘法、rank<br>更复杂一些的例子，例如“使用一般矩阵计算批量的矩阵-矩阵乘积”，‘使用高斯复杂度降低算法计算一般矩阵的矩阵-矩阵乘积’<br>API介绍：<a href="https://docs.nvidia.com/cuda/cublas/index.html">https://docs.nvidia.com/cuda/cublas/index.html</a></p><p>样例代码：<a href="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLAS">https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLAS</a></p><p>功能：</p><p>向量和矩阵操作：包括向量加法、向量-标量乘法、向量点积等。<br>矩阵乘法：支持各种形式的矩阵乘法，包括方阵乘法、矩阵-向量乘法等。<br>分解和求逆：例如LU分解、Cholesky分解和矩阵求逆等。<br>求解线性系统：使用不同的方法解决线性方程组。</p><h3 id="实例程序："><a href="#实例程序：" class="headerlink" title="实例程序："></a>实例程序：</h3><p>计算三角带状矩阵向量乘法</p><p><a href="https://blog.csdn.net/prinTao/article/details/135634551">【cuda】六、基础库：cuBLAS入门-CSDN博客</a></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdlib&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vector&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hipblas.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime_api.h&gt;</span></span><br><br><span class="hljs-comment">//#include &lt;hipblas_utils.h&gt;</span><br><br><span class="hljs-keyword">using</span> data_type = <span class="hljs-type">double</span>; <span class="hljs-comment">//数据类型为double</span><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc,<span class="hljs-type">char</span> *argv[])</span></span>&#123;<br><span class="hljs-comment">//声明一个hipBLAS句柄</span><br>hipblasHandle_t hipblasH = <span class="hljs-literal">NULL</span>;<br><span class="hljs-comment">//声明一个HIP 流</span><br>hipStream_t stream = <span class="hljs-literal">NULL</span>;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> m = <span class="hljs-number">2</span>;<span class="hljs-comment">//矩阵A的行数</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> n = <span class="hljs-number">2</span>;<span class="hljs-comment">//矩阵A的列数</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> k = <span class="hljs-number">1</span>;<span class="hljs-comment">//定义超对角线元素的个数（用于三角矩阵的函数）</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> lda = m;<span class="hljs-comment">//定义矩阵A的领先维度（leading dimension）</span><br><br><span class="hljs-comment">//初始化矩阵A和向量x</span><br><span class="hljs-comment">//std::vector 是c++标准库中的动态数组类，可以存储动态变化数量的元素</span><br><span class="hljs-type">const</span> std::vector&lt;data_type&gt; A = &#123;<span class="hljs-number">1.0</span>,<span class="hljs-number">3.0</span>,<span class="hljs-number">2.0</span>,<span class="hljs-number">4.0</span>&#125;;<br>std::vector&lt;data_type&gt; x = &#123;<span class="hljs-number">5.0</span>,<span class="hljs-number">6.0</span>&#125;;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> incx = <span class="hljs-number">1</span>;<span class="hljs-comment">//x的步长</span><br><br>data_type *d_A = <span class="hljs-literal">nullptr</span>;<span class="hljs-comment">//设备端的矩阵A</span><br>data_type *d_x = <span class="hljs-literal">nullptr</span>;<span class="hljs-comment">//设备端的向量x</span><br><br><span class="hljs-comment">//hipBLAS的相关设置</span><br>hipblasFillMode_t uplo = HIPBLAS_FILL_MODE_UPPER;<span class="hljs-comment">//使用上三角形式</span><br>hipblasOperation_t transa = HIPBLAS_OP_N;<span class="hljs-comment">//矩阵A不进行转置</span><br>hipblasDiagType_t diag = HIPBLAS_DIAG_NON_UNIT;<span class="hljs-comment">//矩阵A的对角线元素不被视为1</span><br><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;A\n&quot;</span>);<br><span class="hljs-comment">//print_matrix(m,n,A.data(),lda);</span><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;======\n&quot;</span>);<br><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;x\n&quot;</span>);<br><span class="hljs-comment">//print_vector(x.size(),x.data());</span><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;=====\n&quot;</span>);<br><br><span class="hljs-comment">//step1</span><br><span class="hljs-comment">//hipblasCreate(&amp;hipblasH);</span><br><br><br><br><br><br><br><br><span class="hljs-keyword">return</span> EXIT_SUCCESS;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="卡住了，hip和cuda-blas-库不同"><a href="#卡住了，hip和cuda-blas-库不同" class="headerlink" title="卡住了，hip和cuda  blas 库不同"></a>卡住了，hip和cuda  blas 库不同</h3><p>cuda的库#include &lt;cublas_utils.h&gt;在hip中#include &lt;hipblas_utils.h&gt;，不能调用</p><p>所以后面的一些库函数也无法调用。</p><p>cublas:</p><p>API介绍：<a href="https://docs.nvidia.com/cuda/cublas/index.html">https://docs.nvidia.com/cuda/cublas/index.html</a></p><p>样例代码：<a href="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLAS">https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLAS</a></p><p>hipblas:</p><p><a href="https://rocmdocs.amd.com/projects/hipBLAS/en/latest/index.html">hipBLAS documentation — hipBLAS 2.1.0 Documentation (amd.com)</a></p><p>有时间再研究吧。。。。。</p><p>先用cuda试试</p><p>因为比赛是用的dcu卡，要用hip，这个方法以后再研究。</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>reduce优化(补充)</title>
    <link href="/2024/06/30/reduce%E4%BC%98%E5%8C%96(%E8%A1%A5%E5%85%85)/"/>
    <url>/2024/06/30/reduce%E4%BC%98%E5%8C%96(%E8%A1%A5%E5%85%85)/</url>
    
    <content type="html"><![CDATA[<h3 id="优化6：调整Block大小"><a href="#优化6：调整Block大小" class="headerlink" title="优化6：调整Block大小"></a>优化6：调整Block大小</h3><p>保持每个block的线程数不变，一个线程处理一个数据，两个数据，四个数据。处理多少个数据比较合适呢，这个就需要试了，获得最优的NumPerThread取值。每个线程处理数据增大一倍，同时blockPerGrid 就要减少一倍。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce6</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock];<br>        <span class="hljs-comment">// 数组的全局索引也要变</span><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * (blockDim.x * NumPerThread);<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        <span class="hljs-comment">// 累加一个线程处理的数据</span><br>        <span class="hljs-comment">// 一定要加上这句,确保在开始累加数据之前，它的值是 0</span><br>        sdata[tid] = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j&lt;NumPerThread;j++)&#123;<br>                sdata[tid] += d_in[i + blockDim.x * j];<br>        &#125;<br>        __syncthreads();<br><br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">1024</span> &amp;&amp; tid &lt; <span class="hljs-number">512</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">512</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">512</span> &amp;&amp; tid &lt; <span class="hljs-number">256</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">256</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">256</span> &amp;&amp; tid &lt; <span class="hljs-number">128</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">128</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">128</span> &amp;&amp; tid &lt; <span class="hljs-number">64</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">64</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid &lt; <span class="hljs-number">32</span>)&#123;<br>                <span class="hljs-built_in">warpReduce</span>(sdata,tid);<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid == <span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br>&#125;<br><br>reduce6&lt;&lt;&lt;blocksPerGrid/NumPerThread,threadsPerBlock&gt;&gt;&gt;(d_a,d_partial_c);<br></code></pre></td></tr></table></figure><h3 id="优化7：shuffle指令"><a href="#优化7：shuffle指令" class="headerlink" title="优化7：shuffle指令"></a>优化7：shuffle指令</h3><h4 id="shuffle指令"><a href="#shuffle指令" class="headerlink" title="shuffle指令"></a>shuffle指令</h4><p>NV提出了Shuffle指令，对于reduce优化有着非常好的效果。目前绝大多数访存类算子，像是softmax，batch_norm，reduce等，都是用Shuffle实现。所以，在这里谈一下这么把shuffle指令用在reduce优化上。</p><p>Shuffle指令是一组针对warp的指令。Shuffle指令最重要的特性就是<strong>warp内的寄存器可以相互访问</strong>。在没有shuffle指令的时候，各个线程在进行通信时只能通过shared memory来访问彼此的寄存器。而采用了shuffle指令之后，<strong>warp内的线程可以直接对其他线程的寄存器进行访存</strong>。通过这种方式可以减少访存的延时。除此之外，带来的最大好处就是可编程性提高了，在某些场景下，<strong>就不用shared memory</strong>了。毕竟，开发者要自己去控制 shared memory还是挺麻烦的一个事。</p><p>以后有时间再研究</p>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>reduce逐步优化</title>
    <link href="/2024/06/29/reduce%E4%BC%98%E5%8C%96/"/>
    <url>/2024/06/29/reduce%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h3 id="参考材料"><a href="#参考材料" class="headerlink" title="参考材料"></a>参考材料</h3><p><a href="https://zhuanlan.zhihu.com/p/426978026">深入浅出GPU优化系列：reduce优化 - 知乎 (zhihu.com)</a></p><h3 id="reduce-baseline-算法（基础规约算法）"><a href="#reduce-baseline-算法（基础规约算法）" class="headerlink" title="reduce baseline 算法（基础规约算法）"></a>reduce baseline 算法（基础规约算法）</h3><p>我们让Num_per_block与Thread_per_block一致，即一个线程处理一个数据，每个block设定为256个线程，一个block负责256个数据的reduce工作。</p><p>假设要处理32M（32*1024）个数据，那么需要的block数为 32M&#x2F;256 &#x3D; 128 个block。</p><p>tid代表每个block里面的线程号，i代表原数组的索引号，将原数组的值分配到每个shared memory 中</p><p>sdata[tid] &#x3D; d_in[i]</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;hip/hip_runtime_api.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> N 32768</span><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> threadsPerBlock = <span class="hljs-number">256</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> blocksPerGrid = <span class="hljs-number">128</span>;<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce0</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>__shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock];<br><br><span class="hljs-comment">//each thread loads one element form global memory to shared memory</span><br><span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;<br><span class="hljs-type">int</span> tid = threadIdx.x;<br>sdata[tid] = d_in[i];<br>__syncthreads();<br><br><span class="hljs-comment">//do reduction in shared memory</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = <span class="hljs-number">1</span>;s&lt;blockDim.x;s*=<span class="hljs-number">2</span>)&#123;<br><span class="hljs-keyword">if</span>(tid%(<span class="hljs-number">2</span>*s)==<span class="hljs-number">0</span>)&#123;<br>sdata[tid] += sdata[tid+s];<br>&#125;<br>__syncthreads();<br>&#125;<br><br><span class="hljs-comment">//wirte result for this block to global memory</span><br><span class="hljs-keyword">if</span>(tid ==<span class="hljs-number">0</span>)&#123;<br>d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>&#125;<br><br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>&#123;<br><br><span class="hljs-type">int</span> a[N],partial_c[blocksPerGrid];<br><span class="hljs-type">long</span> c;<br><span class="hljs-type">int</span> *d_a,*d_partial_c;<br><span class="hljs-built_in">hipMalloc</span>((<span class="hljs-type">void</span> **)&amp;d_a,N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><span class="hljs-built_in">hipMalloc</span>((<span class="hljs-type">void</span> **)&amp;d_partial_c,blocksPerGrid*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>));<br><span class="hljs-comment">//initial</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;N;i++)&#123;<br>a[i] = i;<br>&#125;<br><span class="hljs-built_in">hipMemcpy</span>(d_a,a,N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyHostToDevice);<br>reduce0&lt;&lt;&lt;blocksPerGrid,threadsPerBlock&gt;&gt;&gt;(d_a,d_partial_c);<br><span class="hljs-built_in">hipMemcpy</span>(partial_c,d_partial_c,blocksPerGrid*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">int</span>),hipMemcpyDeviceToHost);<br><br>c = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i&lt;blocksPerGrid;i++)&#123;<br>c += partial_c[i];<br>&#125;<br><br><span class="hljs-built_in">hipFree</span>(d_a);<br><span class="hljs-built_in">hipFree</span>(d_partial_c);<br><br><span class="hljs-comment">//check the result</span><br><span class="hljs-keyword">if</span>(c==<span class="hljs-number">32767</span>*<span class="hljs-number">32768</span>/<span class="hljs-number">2</span>)&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;success\n&quot;</span>);<br>&#125;<span class="hljs-keyword">else</span>&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;fail\n&quot;</span>);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;c=%ld&quot;</span>,c);<br>&#125;<br><br><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br><br>&#125;<br><br><br></code></pre></td></tr></table></figure><h3 id="what-is-warp-and-bank"><a href="#what-is-warp-and-bank" class="headerlink" title="what is warp and bank"></a>what is warp and bank</h3><h4 id="warp"><a href="#warp" class="headerlink" title="warp:"></a>warp:</h4><p>并行计算时最小的并发结构，通常由连续32个thread组成,也称线程束。</p><h4 id="bank"><a href="#bank" class="headerlink" title="bank:"></a>bank:</h4><p>是对SM中共享内存的划分，划分个数与对应硬件warp中所含thread数一致。对应使用的计算能力3.x版本的显卡，一个warp含有32个thread，因此划分的bank数也为32，并且每个bank的宽度大小为4bytes，对应于一个int型或float型变量。</p><h3 id="优化1：解决warp-divergence"><a href="#优化1：解决warp-divergence" class="headerlink" title="优化1：解决warp divergence"></a>优化1：解决warp divergence</h3><h4 id="warp-divergence："><a href="#warp-divergence：" class="headerlink" title="warp divergence："></a>warp divergence：</h4><p>对于同一个warp中的所有thread是完全并行的，且必须要执行相同的指令，当同一warp中的thread分配了不同的指令时，会发生warp divergence，增加了程序的运行时间。为了有效地解决上述divergence问题，在分配任务时，尽量的使用索引号连续的thread，使活跃的thread全部集中到某些warp中，避免同一warp中同时存在活跃和不活跃两种状态的thread。</p><p>对于reduce算法问题，如果存在if-else这样的分支情况的话，thread会执行所有的分支。只是不满足条件的分支，所产生的结果不会记录下来。可以在图中看到，在每一轮迭代中都会产生两个分支，分别是红色和橙色的分支。这严重影响了代码执行的效率。其中红色的线程是符合if条件的线程，只有他们需要干活。</p><p><img src="/../images/1719653482706.png" alt="1719653482706"></p><h4 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h4><p>解决的方式也比较明了，就是尽可能地让所有线程走到同一个分支里面。</p><p>虽然代码依旧存在着if语句，但是却与reduce0代码有所不同。我们继续假定block中存在256个thread，即拥有256&#x2F;32&#x3D;8个warp。由于blockDim.x &#x3D; 256。对于3号warp，index &#x3D; 2乘tid&#x3D;2乘4乘32&#x3D;256，正好到第三个warp。当进行<strong>第1次迭代</strong>时，0-3号warp的index&lt;blockDim.x， 4-7号warp的index&gt;&#x3D;blockDim.x。对于每个warp而言，都只是进入到一个分支内，所以并不会存在warp divergence的情况。当进行<strong>第2次迭代</strong>时，0、1号两个warp进入计算分支。当进行<strong>第3次迭代</strong>时，只有0号warp进入计算分支。当进行<strong>第4次迭代</strong>时，只有0号warp的前16个线程进入分支。此时开始产生warp divergence。通过这种方式，我们消除了前3次迭代的warp divergence。</p><p>这样第一轮迭代只有前3个warp里面的连续线程是忙碌的，消除了warp divergence</p><h4 id="优化代码："><a href="#优化代码：" class="headerlink" title="优化代码："></a>优化代码：</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce1</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>__shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock];<br><br><span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;<br><span class="hljs-type">int</span> tid = threadIdx.x;<br>sdata[tid] = d_in[i];<br>__syncthreads();<br><span class="hljs-comment">//do reduction in shared memory</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = <span class="hljs-number">1</span>;s&lt;blockDim.x;s*=<span class="hljs-number">2</span>)&#123;<br><span class="hljs-type">int</span> index = <span class="hljs-number">2</span>*tid*s;<br><span class="hljs-keyword">if</span>(index &lt; blockDim.x)&#123;<br>sdata[index] += sdata[index+s];<br>&#125;<br>__syncthreads();<br>&#125;<br><span class="hljs-comment">//wirte result for this block to global memory</span><br><span class="hljs-keyword">if</span>(tid == <span class="hljs-number">0</span>)&#123;<br>d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="优化2：解决bank冲突"><a href="#优化2：解决bank冲突" class="headerlink" title="优化2：解决bank冲突"></a>优化2：解决bank冲突</h3><h4 id="bank-conflict"><a href="#bank-conflict" class="headerlink" title="bank conflict:"></a>bank conflict:</h4><p> 一个SM中，共享内存会被分成多个bank，共享内存中以每4*32bytes为单位，顺序的存储在bank0~bank31中，当两个不同的thread同时访问同一bank内的值时，会发生bank conflict，也会增加程序运行的时间。</p><h4 id="解决思路-1"><a href="#解决思路-1" class="headerlink" title="解决思路"></a>解决思路</h4><p>reduce1的最大问题是<strong>bank冲突</strong>。我们把目光聚焦在这个for循环中。并且只聚焦在<strong>0号warp</strong>。在<strong>第一次迭代</strong>中，0号线程需要去load shared memory的0号地址以及1号地址的数，然后写回到0号地址。而此时，这个warp中的16号线程，需要去load shared memory中的32号地址和33号地址。可以发现，0号地址跟32号地址产生了<strong>2路的bank冲突</strong>。再往后迭代会出现更多路的bank冲突</p><p>slove：</p><p>在reduce中，解决bank冲突的方式就是把for循环逆着来。原来stride从0到256，现在stride从128到0。</p><p>把目光继续看到这个for循环中，并且只分析0号warp。0号线程需要load shared memory的0号元素以及128号元素。第2轮迭代，0号线程load 0号元素和64号元素，1号线程load 1号元素和65号元素。第3轮迭代，0号线程load 0号元素和32号元素。到了4轮迭代，0号线程load 0号元素和16号元素。15号线程load 15号元素和31号元素。那16号线程呢，16号线程啥也不干，因为s&#x3D;16，16-31号线程啥也不干，跳过去了。</p><h4 id="优化代码"><a href="#优化代码" class="headerlink" title="优化代码"></a>优化代码</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce2</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock];<br><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        sdata[tid] = d_in[i];<br>        __syncthreads();<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = blockDim.x/<span class="hljs-number">2</span>;s&gt;<span class="hljs-number">0</span>;s/=<span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-keyword">if</span>(tid&lt;s)&#123;<br>                        sdata[tid] += sdata[tid+s];<br>                &#125;<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid==<span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="优化3：解决idle线程"><a href="#优化3：解决idle线程" class="headerlink" title="优化3：解决idle线程"></a>优化3：解决idle线程</h3><p>reduce2最大的问题就是线程的浪费。可以看到我们启动了256个线程，但是在第1轮迭代时只有128个线程在干活，第2轮迭代只有64个线程在干活，每次干活的线程都会减少一半。第一轮迭代示意图如下，只有前128个线程在load数据。后128个线程啥也不干，光看着。</p><p>每一轮迭代都有一半的线程不工作，要把所有的线程利用起来。</p><p>想来想去，那这样吧，让它好歹做一次加法。除了去global memory中取数外，再做一次加法。当然为了实现这个，block数就得改一改了。Block数量减少，Num_per_block增加一倍。也就是说原来一个block只需要管256个数就行，现在得管512个数了。</p><p>每个block还是256个线程，不同的地方在于每个block里边会处理512个数据，这样一来grid中block的数量也减少了一半。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce3</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock*<span class="hljs-number">2</span>];<br><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * (blockDim.x*<span class="hljs-number">2</span>);<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        sdata[tid] = d_in[i] + d_in[i + blockDim.x];<br>        __syncthreads();<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = blockDim.x/<span class="hljs-number">2</span>;s&gt;<span class="hljs-number">0</span>;s/=<span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-keyword">if</span>(tid&lt;s)&#123;<br>                        sdata[tid] += sdata[tid + s];<br>                &#125;<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid==<span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br><br>&#125;<br><br>reduce3&lt;&lt;&lt;blocksPerGrid/<span class="hljs-number">2</span>,threadsPerBlock&gt;&gt;&gt;(d_a,d_partial_c);<br></code></pre></td></tr></table></figure><h3 id="优化4：展开最后一维减少同步"><a href="#优化4：展开最后一维减少同步" class="headerlink" title="优化4：展开最后一维减少同步"></a>优化4：展开最后一维减少同步</h3><p>线程每一次迭代都减半。由于一个warp中的32个线程其实是在一个SIMD单元上，这32个线程每次都是执行同一条指令，这天然地保持了同步状态。当线程束&gt;32时需要同步，反之线程数&lt;32时，就不需要同步了。我们需要在这个时候将syncthreads操作去掉，减少同步所造成的时间浪费。</p><p>所以我们将最后一维进行展开以减少同步。</p><p>需要注意的是<strong>这个地方的cache变量需要使用volatile来进行声明</strong>，它告诉编译器每次赋值时必须将cache[tid]的值返回到全局内存中，而不是简单的读写缓存或寄存器。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//__global__是kernel函数，可从cpu调用,__device__是只能从一个gpu函数调用，不能从cpu调用</span><br><span class="hljs-comment">//volatile 指出变量是随时可能发生变化的,与volatile变量有关的运算,不要进行编译优化,以免出错</span><br><span class="hljs-function">__device__ <span class="hljs-type">void</span> <span class="hljs-title">warpReduce</span><span class="hljs-params">(<span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> *cache,<span class="hljs-type">int</span> tid)</span></span>&#123;<br>        cache[tid] += cache[tid+<span class="hljs-number">32</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">16</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">8</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">4</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">2</span>];<br>        cache[tid] += cache[tid+<span class="hljs-number">1</span>];<br>&#125;<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce4</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock*<span class="hljs-number">2</span>];<br><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * (blockDim.x*<span class="hljs-number">2</span>);<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        sdata[tid] = d_in[i] + d_in[i + blockDim.x];<br>        __syncthreads();<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> s = blockDim.x/<span class="hljs-number">2</span>;s&gt;<span class="hljs-number">32</span>;s/=<span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-keyword">if</span>(tid&lt;s)&#123;<br>                        sdata[tid] += sdata[tid + s];<br>                &#125;<br>                __syncthreads();<br><br>        &#125;<br>        <span class="hljs-comment">//此时s = 32,因为tid&lt;s,只有一个warp里面32个线程了</span><br>        <span class="hljs-keyword">if</span>(tid&lt;<span class="hljs-number">32</span>)&#123;<br>                <span class="hljs-built_in">warpReduce</span>(sdata,tid);<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid==<span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="优化5：完全展开"><a href="#优化5：完全展开" class="headerlink" title="优化5：完全展开"></a>优化5：完全展开</h3><p>对<strong>for循环</strong>进行完全展开，通过这种方式<strong>减少了条件判断的次数</strong>，因而可以实现速度的提升。</p><p>效果一般</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//reduce 完全展开</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">reduce5</span><span class="hljs-params">(<span class="hljs-type">int</span> *d_in,<span class="hljs-type">int</span> *d_out)</span></span>&#123;<br>        __shared__ <span class="hljs-type">int</span> sdata[threadsPerBlock*<span class="hljs-number">2</span>];<br><br>        <span class="hljs-type">int</span> i = threadIdx.x + blockIdx.x * (blockDim.x*<span class="hljs-number">2</span>);<br>        <span class="hljs-type">int</span> tid = threadIdx.x;<br>        sdata[tid] = d_in[i] + d_in[i + blockDim.x];<br>        __syncthreads();<br><br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">1024</span> &amp;&amp; tid &lt; <span class="hljs-number">512</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">512</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">512</span> &amp;&amp; tid &lt; <span class="hljs-number">256</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">256</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;= <span class="hljs-number">256</span> &amp;&amp; tid &lt; <span class="hljs-number">128</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">128</span>];<br>                __syncthreads();<br>        &#125;<br>        <span class="hljs-keyword">if</span>(blockDim.x &gt;=<span class="hljs-number">128</span> &amp;&amp; tid &lt; <span class="hljs-number">64</span>)&#123;<br>                sdata[tid] += sdata[tid + <span class="hljs-number">64</span>];<br>                __syncthreads();<br>        &#125;<br><br>        <span class="hljs-keyword">if</span>(tid &lt; <span class="hljs-number">32</span>)&#123;<br>                <span class="hljs-built_in">warpReduce</span>(sdata,tid);<br>        &#125;<br>        <span class="hljs-keyword">if</span>(tid == <span class="hljs-number">0</span>)&#123;<br>                d_out[blockIdx.x] = sdata[<span class="hljs-number">0</span>];<br>        &#125;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="优化6：调整Block大小"><a href="#优化6：调整Block大小" class="headerlink" title="优化6：调整Block大小"></a>优化6：调整Block大小</h3><h3 id="优化7：shuffle指令"><a href="#优化7：shuffle指令" class="headerlink" title="优化7：shuffle指令"></a>优化7：shuffle指令</h3>]]></content>
    
    
    <categories>
      
      <category>hpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>天气晴，明天有雨</title>
    <link href="/2024/06/28/%E9%9A%8F%E7%AC%941/"/>
    <url>/2024/06/28/%E9%9A%8F%E7%AC%941/</url>
    
    <content type="html"><![CDATA[<h4 id="搭建了我的博客"><a href="#搭建了我的博客" class="headerlink" title="搭建了我的博客"></a>搭建了我的博客</h4><p>github 文章永生</p><p>明天加油吧！！！</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>日记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>流体力学</title>
    <link href="/2024/06/28/%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/"/>
    <url>/2024/06/28/%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/</url>
    
    <content type="html"><![CDATA[<p>学习记录</p><p>1.流体研究的前提：连续介质假设<br>2.流体力学的物理量：速度，密度，压强，温度等</p><h3 id="描述流体运动的方法："><a href="#描述流体运动的方法：" class="headerlink" title="描述流体运动的方法："></a>描述流体运动的方法：</h3><p>①拉格朗日法：以一坨流体的某个质点为例，研究这个质点的随时间的变化，即盯着质点看。<br>②欧拉法：在空间取一个范围，即控制体，控制体（固定不动），如控制体中取某位置，研究该位置所在流体的性质，也就是盯着空间看。<br>●总结：拉格朗日法研究的是一坨流体（积分）或者说某个质点（微分）；欧拉法研究的是控制体（积分）或空间点（微分）</p><p><img src="/../images/1713422480785.png" alt="1713422480785"></p><h3 id="流体力学的任务（要解决什么问题）"><a href="#流体力学的任务（要解决什么问题）" class="headerlink" title="流体力学的任务（要解决什么问题）"></a>流体力学的任务（要解决什么问题）</h3><p>例子：血栓的形成，航天器内部气体的流动</p><p>研究一定条件下，任意时刻（t），任意位置（x,y,z）各种物理量（p，ρ，T，v）的分布</p><p>p(x,y,z,t),ρ（x,y,z,t）…..解这些函数，就涉及流体力学的基本方程。</p><h3 id="流体力学的基本方程（控制方程）"><a href="#流体力学的基本方程（控制方程）" class="headerlink" title="流体力学的基本方程（控制方程）"></a>流体力学的基本方程（控制方程）</h3><p>是一个方程组。</p><p>质量守恒</p><p>动量守恒（动量有三个方向，可以列三个方程）</p><p>能量守恒</p><p>要解6个值 P,ρ，T，t，v（u,v,w）速度有三个方向，一共是6个值</p><p>一共是5个方程，所以还要加一个流体力学本身具有的性质所列出的方程。</p><p><img src="/../images/1713423733375.png" alt="1713423733375"></p><h3 id="质量守恒方程（连续方程）"><a href="#质量守恒方程（连续方程）" class="headerlink" title="质量守恒方程（连续方程）"></a>质量守恒方程（连续方程）</h3><h4 id="积分形式的质量守恒"><a href="#积分形式的质量守恒" class="headerlink" title="积分形式的质量守恒"></a>积分形式的质量守恒</h4><p><img src="/../images/1713516753303.png" alt="1713516753303"></p><p><img src="/../images/1713516816649.png" alt="1713516816649"></p><h4 id="微分形式的质量守恒方程"><a href="#微分形式的质量守恒方程" class="headerlink" title="微分形式的质量守恒方程"></a>微分形式的质量守恒方程</h4><p><img src="/../images/1713516848847.png" alt="1713516848847"></p><p><img src="/../images/1713517551714.png" alt="1713517551714"></p><h4 id="散度和梯度"><a href="#散度和梯度" class="headerlink" title="散度和梯度"></a>散度和梯度</h4><p><img src="/../images/1713517596596.png" alt="1713517596596"></p><p><img src="/../images/1713517639356.png" alt="1713517639356"></p><h4 id="两种特殊情况"><a href="#两种特殊情况" class="headerlink" title="两种特殊情况"></a>两种特殊情况</h4><p>定常流动：流动是稳定的，不随时间而改变</p><p><img src="/../images/1713518306247.png" alt="1713518306247"></p><p>不可压流动：ρ为常数</p><h5 id=""><a href="#" class="headerlink" title=""></a><img src="/../images/1713518419990.png" alt="1713518419990"></h5><h4 id="连续方程微分形式的第二种推导方法"><a href="#连续方程微分形式的第二种推导方法" class="headerlink" title="连续方程微分形式的第二种推导方法"></a>连续方程微分形式的第二种推导方法</h4><p>略</p><p>散度的物理意义：</p><p><img src="/../images/1713520658383.png" alt="1713520658383"></p><p>速度散度：单位体积单位时间的体积变化</p><p><img src="/../images/1713520754996.png" alt="1713520754996"></p><h4 id="定常准一维流动的连续方程"><a href="#定常准一维流动的连续方程" class="headerlink" title="定常准一维流动的连续方程"></a>定常准一维流动的连续方程</h4><p>ρuA&#x3D;常数</p><p><img src="/../images/1713522073052.png" alt="1713522073052"></p><h3 id="动量守恒方程"><a href="#动量守恒方程" class="headerlink" title="动量守恒方程"></a>动量守恒方程</h3><h3 id="能量守恒方程"><a href="#能量守恒方程" class="headerlink" title="能量守恒方程"></a>能量守恒方程</h3>]]></content>
    
    
    <categories>
      
      <category>cfd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>cfd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo_github遇到的问题</title>
    <link href="/2024/06/28/hexo_github%E9%85%8D%E7%BD%AE/"/>
    <url>/2024/06/28/hexo_github%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h3 id="冒号后面要加空格"><a href="#冒号后面要加空格" class="headerlink" title="冒号后面要加空格"></a>冒号后面要加空格</h3><h3 id="repo写以下格式"><a href="#repo写以下格式" class="headerlink" title="repo写以下格式"></a>repo写以下格式</h3><p><img src="/../images/1719557282413.png"></p><h3 id="master分支设置"><a href="#master分支设置" class="headerlink" title="master分支设置"></a>master分支设置</h3><p><img src="/../images/1719557364439.png"></p><p><img src="/../images/1719557376929.png"></p>]]></content>
    
    
    <categories>
      
      <category>喜欢捣鼓</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>加载图片，研究一下</title>
    <link href="/2024/06/28/%E5%8A%A0%E8%BD%BD%E5%9B%BE%E7%89%87/"/>
    <url>/2024/06/28/%E5%8A%A0%E8%BD%BD%E5%9B%BE%E7%89%87/</url>
    
    <content type="html"><![CDATA[<p><img src="/../images/a.jpeg" alt="车"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/06/25/hello-world/"/>
    <url>/2024/06/25/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
